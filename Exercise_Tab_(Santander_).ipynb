{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise Tab  (Santander )",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitsharhcl/fastai-v3/blob/master/Exercise_Tab_(Santander_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8VA417-qM2st",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###LGBM GPU"
      ]
    },
    {
      "metadata": {
        "id": "lXYgXHDDQf89",
        "colab_type": "code",
        "outputId": "8dd77bde-a12d-4723-86e3-18efbf87f322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 13225 (delta 0), reused 0 (delta 0), pack-reused 13224\u001b[K\n",
            "Receiving objects: 100% (13225/13225), 9.42 MiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (9415/9415), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
            "Cloning into '/content/LightGBM/compute'...\n",
            "remote: Enumerating objects: 33, done.        \n",
            "remote: Counting objects: 100% (33/33), done.        \n",
            "remote: Compressing objects: 100% (21/21), done.        \n",
            "remote: Total 21689 (delta 12), reused 23 (delta 9), pack-reused 21656        \n",
            "Receiving objects: 100% (21689/21689), 8.51 MiB | 5.89 MiB/s, done.\n",
            "Resolving deltas: 100% (17532/17532), done.\n",
            "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sv2G-Rak7BBl",
        "colab_type": "code",
        "outputId": "feb19abb-04b4-42bd-8f4a-ed1c17fe71d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ynBWKna37PqL",
        "colab_type": "code",
        "outputId": "364f148c-671a-4235-cb42-2bc5421273cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/LightGBM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2xClK8ak7Q7s",
        "colab_type": "code",
        "outputId": "eb699f24-80ef-411b-9097-6c408b2a32ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 96\n",
            "-rw-r--r-- 1 root root 2359 Apr  9 06:31 build_r.R\n",
            "-rw-r--r-- 1 root root 8956 Apr  9 06:31 CMakeLists.txt\n",
            "-rw-r--r-- 1 root root 4687 Apr  9 06:31 CODE_OF_CONDUCT.md\n",
            "drwxr-xr-x 9 root root 4096 Apr  9 06:32 compute\n",
            "drwxr-xr-x 3 root root 4096 Apr  9 06:31 docker\n",
            "drwxr-xr-x 3 root root 4096 Apr  9 06:31 docs\n",
            "drwxr-xr-x 8 root root 4096 Apr  9 06:31 examples\n",
            "drwxr-xr-x 2 root root 4096 Apr  9 06:31 helpers\n",
            "drwxr-xr-x 3 root root 4096 Apr  9 06:31 include\n",
            "-rw-r--r-- 1 root root 1085 Apr  9 06:31 LICENSE\n",
            "drwxr-xr-x 2 root root 4096 Apr  9 06:31 pmml\n",
            "drwxr-xr-x 3 root root 4096 Apr  9 06:31 python-package\n",
            "-rw-r--r-- 1 root root 9081 Apr  9 06:31 README.md\n",
            "drwxr-xr-x 9 root root 4096 Apr  9 06:31 R-package\n",
            "drwxr-xr-x 9 root root 4096 Apr  9 06:31 src\n",
            "drwxr-xr-x 2 root root 4096 Apr  9 06:31 swig\n",
            "drwxr-xr-x 6 root root 4096 Apr  9 06:31 tests\n",
            "-rw-r--r-- 1 root root    6 Apr  9 06:31 VERSION.txt\n",
            "drwxr-xr-x 2 root root 4096 Apr  9 06:31 windows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xryhftNi7U4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zK9kONk7czA",
        "colab_type": "code",
        "outputId": "be9499d6-dc23-4e72-ddf1-06c47c71b90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "cell_type": "code",
      "source": [
        "!cmake -DUSE_GPU=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.3.0\n",
            "-- The CXX compiler identification is GNU 7.3.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory:/usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AqJa16mK7rbD",
        "colab_type": "code",
        "outputId": "0aa93e3a-bd37-4676-ca70-d5aa336418c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1268
        }
      },
      "cell_type": "code",
      "source": [
        "!make -j$(nproc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/lightgbm_R.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
            "[ 98%] Built target lightgbm\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
            "[100%] Built target _lightgbm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PIFQcedY7s3f",
        "colab_type": "code",
        "outputId": "a202bbb7-33cd-4f3d-9b35-d3ebaa9a1476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2719
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo apt-get -y install python-pip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 3,376 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.2 [221 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1 [1,652 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,376 kB in 15s (229 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.2_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-wl_GYos7zyv",
        "colab_type": "code",
        "outputId": "f078e2a3-108b-422a-eec5-f71ca66f71db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/b0/cc6b7ba28d5fb790cf0d5946df849233e32b8872b6baca10c9e002ff5b41/setuptools-41.0.0-py2.py3-none-any.whl (575kB)\n",
            "\u001b[K    100% |████████████████████████████████| 583kB 23.5MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 3.6MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 2.0MB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 24.8MB 1.1MB/s \n",
            "\u001b[?25hRequirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setuptools, numpy, pandas, scipy\n",
            "  Found existing installation: setuptools 40.9.0\n",
            "    Uninstalling setuptools-40.9.0:\n",
            "      Successfully uninstalled setuptools-40.9.0\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "  Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "Successfully installed numpy-1.16.2 pandas-0.24.2 scipy-1.2.1 setuptools-41.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bzodnkYL8A9X",
        "colab_type": "code",
        "outputId": "c79b6421-07dc-4538-fb51-5cffb5c86eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd python-package/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM/python-package\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vJ-WZ49g8Clv",
        "colab_type": "code",
        "outputId": "1c173b17-d953-479f-da5a-c1e100616fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1194
        }
      },
      "cell_type": "code",
      "source": [
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-2.2.4-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g87ozMTcHFmM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###TEST"
      ]
    },
    {
      "metadata": {
        "id": "OVoXInNzHIns",
        "colab_type": "code",
        "outputId": "1f0ba143-8664-4f3c-ef0d-29c80f9d76cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM/python-package\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hdf-ChpdHIjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LA2fNcL09PuI",
        "colab_type": "code",
        "outputId": "16f0f147-5e49-4a69-96e9-186b4c3617bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print('Loading data...')\n",
        "# load or create your dataset\n",
        "df_train = pd.read_csv('../../regression.train', header=None, sep='\\t')\n",
        "df_test = pd.read_csv('../../regression.test', header=None, sep='\\t')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h43SCaAr9Rkw",
        "colab_type": "code",
        "outputId": "1c1dd934-ec20-4f45-ea7a-f4ee4258dd54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = df_train[0]\n",
        "y_test = df_test[0]\n",
        "X_train = df_train.drop(0, axis=1)\n",
        "X_test = df_test.drop(0, axis=1)\n",
        "\n",
        "# create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'device_type':'gpu',\n",
        "    'metric': {'l2', 'l1'},\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "print('Starting training...')\n",
        "# train\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=20,\n",
        "                valid_sets=lgb_eval,\n",
        "                early_stopping_rounds=5)\n",
        "\n",
        "print('Saving model...')\n",
        "# save model to file\n",
        "gbm.save_model('model.txt')\n",
        "\n",
        "print('Starting predicting...')\n",
        "# predict\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "# eval\n",
        "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "[1]\tvalid_0's l2: 0.243481\tvalid_0's l1: 0.492417\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's l2: 0.240045\tvalid_0's l1: 0.48874\n",
            "[3]\tvalid_0's l2: 0.236636\tvalid_0's l1: 0.485042\n",
            "[4]\tvalid_0's l2: 0.232959\tvalid_0's l1: 0.480872\n",
            "[5]\tvalid_0's l2: 0.229684\tvalid_0's l1: 0.476928\n",
            "[6]\tvalid_0's l2: 0.226942\tvalid_0's l1: 0.473545\n",
            "[7]\tvalid_0's l2: 0.223972\tvalid_0's l1: 0.469984\n",
            "[8]\tvalid_0's l2: 0.220928\tvalid_0's l1: 0.466083\n",
            "[9]\tvalid_0's l2: 0.217949\tvalid_0's l1: 0.462164\n",
            "[10]\tvalid_0's l2: 0.21512\tvalid_0's l1: 0.458352\n",
            "[11]\tvalid_0's l2: 0.212604\tvalid_0's l1: 0.454791\n",
            "[12]\tvalid_0's l2: 0.210518\tvalid_0's l1: 0.451691\n",
            "[13]\tvalid_0's l2: 0.208727\tvalid_0's l1: 0.448774\n",
            "[14]\tvalid_0's l2: 0.207323\tvalid_0's l1: 0.446395\n",
            "[15]\tvalid_0's l2: 0.205937\tvalid_0's l1: 0.443898\n",
            "[16]\tvalid_0's l2: 0.204131\tvalid_0's l1: 0.44107\n",
            "[17]\tvalid_0's l2: 0.202736\tvalid_0's l1: 0.438778\n",
            "[18]\tvalid_0's l2: 0.201232\tvalid_0's l1: 0.436648\n",
            "[19]\tvalid_0's l2: 0.199921\tvalid_0's l1: 0.434139\n",
            "[20]\tvalid_0's l2: 0.198827\tvalid_0's l1: 0.431931\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[20]\tvalid_0's l2: 0.198827\tvalid_0's l1: 0.431931\n",
            "Saving model...\n",
            "Starting predicting...\n",
            "The rmse of prediction is: 0.44590041244694517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zmBBe76QG-lj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Data Load"
      ]
    },
    {
      "metadata": {
        "id": "lpI6xKMv02ch",
        "colab_type": "code",
        "outputId": "7395f6fe-b386-4245-aceb-60577c06bfd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM/python-package\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BSu2C3MgaMXD",
        "colab_type": "code",
        "outputId": "da665cd7-6dfe-4515-cab4-06d3f114a425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!curl --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en,en-US;q=0.5' --referer 'https://www.kaggle.com/' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/10385/298493/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1555095162&Signature=aobqfa8sS6mifE%2FCzdmjQsJ5Bsr0REfjYiwMRf0knodtSNgBUH87oyDEe5ILTyR82LFbKAeHtQlAchVpXsKaQUY%2FYdStpYVK56Fkc538nDZBDA7HbQ3BKXGc52eYLaz1w0OHNkN3RPwKLfA6P8gwai0uGtnnf5UfmJ5dCN4392VkUL6RH1FfS%2BkyKCEkfCRc9jwhq%2BvRD4ifmrB2BKveMIMydpUwbVNnILSXFWINjnwiCkznwvM5rXXgOA4ykEYRqXuk%2BQj7sRDmUlBuNzVCj5QUqaflhq%2B4HK6j94vwDdWOxucCFXUTdGV2p9YEPmEgFi7UTm1RO6f%2FvHgUACTuLw%3D%3D&response-content-disposition=attachment%3B+filename%3Dsantander-customer-transaction-prediction.zip' --output 'santander-customer-transaction-prediction.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  244M  100  244M    0     0  72.4M      0  0:00:03  0:00:03 --:--:-- 72.4M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K4h6W3G8GDxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/sample_data/santander"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1euiI9k1GLpI",
        "colab_type": "code",
        "outputId": "ae30481f-f059-417f-f33c-ca67138e4d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip santander-customer-transaction-prediction.zip -d /content/sample_data/santander"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  santander-customer-transaction-prediction.zip\n",
            "  inflating: /content/sample_data/santander/train.csv  \n",
            "  inflating: /content/sample_data/santander/sample_submission.csv  \n",
            "  inflating: /content/sample_data/santander/test.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hh6fUvFmGRNJ",
        "colab_type": "code",
        "outputId": "e468271b-5525-4d19-9230-9aa1d9064164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "cell_type": "code",
      "source": [
        "path = Path('/content/sample_data/santander');path.ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-355eab9e61e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/santander'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WFh7Pz4jGmrE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/sample_data/santander/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQi2iv799t6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/sample_data/santander/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PYJFNEu7IgNj",
        "colab_type": "code",
        "outputId": "d60d05a6-42c9-4519-8b6a-e5a7eab08fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100490</td>\n",
              "      <td>10.679914</td>\n",
              "      <td>-1.627622</td>\n",
              "      <td>10.715192</td>\n",
              "      <td>6.796529</td>\n",
              "      <td>11.078333</td>\n",
              "      <td>-5.065317</td>\n",
              "      <td>5.408949</td>\n",
              "      <td>16.545850</td>\n",
              "      <td>0.284162</td>\n",
              "      <td>...</td>\n",
              "      <td>3.234440</td>\n",
              "      <td>7.438408</td>\n",
              "      <td>1.927839</td>\n",
              "      <td>3.331774</td>\n",
              "      <td>17.993784</td>\n",
              "      <td>-0.142088</td>\n",
              "      <td>2.303335</td>\n",
              "      <td>8.908158</td>\n",
              "      <td>15.870720</td>\n",
              "      <td>-3.326537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300653</td>\n",
              "      <td>3.040051</td>\n",
              "      <td>4.050044</td>\n",
              "      <td>2.640894</td>\n",
              "      <td>2.043319</td>\n",
              "      <td>1.623150</td>\n",
              "      <td>7.863267</td>\n",
              "      <td>0.866607</td>\n",
              "      <td>3.418076</td>\n",
              "      <td>3.332634</td>\n",
              "      <td>...</td>\n",
              "      <td>4.559922</td>\n",
              "      <td>3.023272</td>\n",
              "      <td>1.478423</td>\n",
              "      <td>3.992030</td>\n",
              "      <td>3.135162</td>\n",
              "      <td>1.429372</td>\n",
              "      <td>5.454369</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>3.010945</td>\n",
              "      <td>10.438015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.453850</td>\n",
              "      <td>-4.740025</td>\n",
              "      <td>8.722475</td>\n",
              "      <td>5.254075</td>\n",
              "      <td>9.883175</td>\n",
              "      <td>-11.200350</td>\n",
              "      <td>4.767700</td>\n",
              "      <td>13.943800</td>\n",
              "      <td>-2.317800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>5.157400</td>\n",
              "      <td>0.889775</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>15.629800</td>\n",
              "      <td>-1.170700</td>\n",
              "      <td>-1.946925</td>\n",
              "      <td>8.252800</td>\n",
              "      <td>13.829700</td>\n",
              "      <td>-11.208475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.524750</td>\n",
              "      <td>-1.608050</td>\n",
              "      <td>10.580000</td>\n",
              "      <td>6.825000</td>\n",
              "      <td>11.108250</td>\n",
              "      <td>-4.833150</td>\n",
              "      <td>5.385100</td>\n",
              "      <td>16.456800</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.203600</td>\n",
              "      <td>7.347750</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>3.396350</td>\n",
              "      <td>17.957950</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>2.408900</td>\n",
              "      <td>8.888200</td>\n",
              "      <td>15.934050</td>\n",
              "      <td>-2.819550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.758200</td>\n",
              "      <td>1.358625</td>\n",
              "      <td>12.516700</td>\n",
              "      <td>8.324100</td>\n",
              "      <td>12.261125</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.102900</td>\n",
              "      <td>2.937900</td>\n",
              "      <td>...</td>\n",
              "      <td>6.406200</td>\n",
              "      <td>9.512525</td>\n",
              "      <td>2.949500</td>\n",
              "      <td>6.205800</td>\n",
              "      <td>20.396525</td>\n",
              "      <td>0.829600</td>\n",
              "      <td>6.556725</td>\n",
              "      <td>9.593300</td>\n",
              "      <td>18.064725</td>\n",
              "      <td>4.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target          var_0          var_1          var_2  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.100490      10.679914      -1.627622      10.715192   \n",
              "std         0.300653       3.040051       4.050044       2.640894   \n",
              "min         0.000000       0.408400     -15.043400       2.117100   \n",
              "25%         0.000000       8.453850      -4.740025       8.722475   \n",
              "50%         0.000000      10.524750      -1.608050      10.580000   \n",
              "75%         0.000000      12.758200       1.358625      12.516700   \n",
              "max         1.000000      20.315000      10.376800      19.353000   \n",
              "\n",
              "               var_3          var_4          var_5          var_6  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        6.796529      11.078333      -5.065317       5.408949   \n",
              "std         2.043319       1.623150       7.863267       0.866607   \n",
              "min        -0.040200       5.074800     -32.562600       2.347300   \n",
              "25%         5.254075       9.883175     -11.200350       4.767700   \n",
              "50%         6.825000      11.108250      -4.833150       5.385100   \n",
              "75%         8.324100      12.261125       0.924800       6.003000   \n",
              "max        13.188300      16.671400      17.251600       8.447700   \n",
              "\n",
              "               var_7          var_8      ...              var_190  \\\n",
              "count  200000.000000  200000.000000      ...        200000.000000   \n",
              "mean       16.545850       0.284162      ...             3.234440   \n",
              "std         3.418076       3.332634      ...             4.559922   \n",
              "min         5.349700     -10.505500      ...           -14.093300   \n",
              "25%        13.943800      -2.317800      ...            -0.058825   \n",
              "50%        16.456800       0.393700      ...             3.203600   \n",
              "75%        19.102900       2.937900      ...             6.406200   \n",
              "max        27.691800      10.151300      ...            18.440900   \n",
              "\n",
              "             var_191        var_192        var_193        var_194  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        7.438408       1.927839       3.331774      17.993784   \n",
              "std         3.023272       1.478423       3.992030       3.135162   \n",
              "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
              "25%         5.157400       0.889775       0.584600      15.629800   \n",
              "50%         7.347750       1.901300       3.396350      17.957950   \n",
              "75%         9.512525       2.949500       6.205800      20.396525   \n",
              "max        16.716500       8.402400      18.281800      27.928800   \n",
              "\n",
              "             var_195        var_196        var_197        var_198  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       -0.142088       2.303335       8.908158      15.870720   \n",
              "std         1.429372       5.454369       0.921625       3.010945   \n",
              "min        -5.261000     -14.209600       5.960600       6.299300   \n",
              "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
              "50%        -0.172700       2.408900       8.888200      15.934050   \n",
              "75%         0.829600       6.556725       9.593300      18.064725   \n",
              "max         4.272900      18.321500      12.000400      26.079100   \n",
              "\n",
              "             var_199  \n",
              "count  200000.000000  \n",
              "mean       -3.326537  \n",
              "std        10.438015  \n",
              "min       -38.852800  \n",
              "25%       -11.208475  \n",
              "50%        -2.819550  \n",
              "75%         4.836800  \n",
              "max        28.500700  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "gecyaksb96fe",
        "colab_type": "code",
        "outputId": "85161e25-7f54-4830-e94e-b18a19fd817d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100490</td>\n",
              "      <td>10.679914</td>\n",
              "      <td>-1.627622</td>\n",
              "      <td>10.715192</td>\n",
              "      <td>6.796529</td>\n",
              "      <td>11.078333</td>\n",
              "      <td>-5.065317</td>\n",
              "      <td>5.408949</td>\n",
              "      <td>16.545850</td>\n",
              "      <td>0.284162</td>\n",
              "      <td>...</td>\n",
              "      <td>3.234440</td>\n",
              "      <td>7.438408</td>\n",
              "      <td>1.927839</td>\n",
              "      <td>3.331774</td>\n",
              "      <td>17.993784</td>\n",
              "      <td>-0.142088</td>\n",
              "      <td>2.303335</td>\n",
              "      <td>8.908158</td>\n",
              "      <td>15.870720</td>\n",
              "      <td>-3.326537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300653</td>\n",
              "      <td>3.040051</td>\n",
              "      <td>4.050044</td>\n",
              "      <td>2.640894</td>\n",
              "      <td>2.043319</td>\n",
              "      <td>1.623150</td>\n",
              "      <td>7.863267</td>\n",
              "      <td>0.866607</td>\n",
              "      <td>3.418076</td>\n",
              "      <td>3.332634</td>\n",
              "      <td>...</td>\n",
              "      <td>4.559922</td>\n",
              "      <td>3.023272</td>\n",
              "      <td>1.478423</td>\n",
              "      <td>3.992030</td>\n",
              "      <td>3.135162</td>\n",
              "      <td>1.429372</td>\n",
              "      <td>5.454369</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>3.010945</td>\n",
              "      <td>10.438015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.453850</td>\n",
              "      <td>-4.740025</td>\n",
              "      <td>8.722475</td>\n",
              "      <td>5.254075</td>\n",
              "      <td>9.883175</td>\n",
              "      <td>-11.200350</td>\n",
              "      <td>4.767700</td>\n",
              "      <td>13.943800</td>\n",
              "      <td>-2.317800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>5.157400</td>\n",
              "      <td>0.889775</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>15.629800</td>\n",
              "      <td>-1.170700</td>\n",
              "      <td>-1.946925</td>\n",
              "      <td>8.252800</td>\n",
              "      <td>13.829700</td>\n",
              "      <td>-11.208475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.524750</td>\n",
              "      <td>-1.608050</td>\n",
              "      <td>10.580000</td>\n",
              "      <td>6.825000</td>\n",
              "      <td>11.108250</td>\n",
              "      <td>-4.833150</td>\n",
              "      <td>5.385100</td>\n",
              "      <td>16.456800</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.203600</td>\n",
              "      <td>7.347750</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>3.396350</td>\n",
              "      <td>17.957950</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>2.408900</td>\n",
              "      <td>8.888200</td>\n",
              "      <td>15.934050</td>\n",
              "      <td>-2.819550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.758200</td>\n",
              "      <td>1.358625</td>\n",
              "      <td>12.516700</td>\n",
              "      <td>8.324100</td>\n",
              "      <td>12.261125</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.102900</td>\n",
              "      <td>2.937900</td>\n",
              "      <td>...</td>\n",
              "      <td>6.406200</td>\n",
              "      <td>9.512525</td>\n",
              "      <td>2.949500</td>\n",
              "      <td>6.205800</td>\n",
              "      <td>20.396525</td>\n",
              "      <td>0.829600</td>\n",
              "      <td>6.556725</td>\n",
              "      <td>9.593300</td>\n",
              "      <td>18.064725</td>\n",
              "      <td>4.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target          var_0          var_1          var_2  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.100490      10.679914      -1.627622      10.715192   \n",
              "std         0.300653       3.040051       4.050044       2.640894   \n",
              "min         0.000000       0.408400     -15.043400       2.117100   \n",
              "25%         0.000000       8.453850      -4.740025       8.722475   \n",
              "50%         0.000000      10.524750      -1.608050      10.580000   \n",
              "75%         0.000000      12.758200       1.358625      12.516700   \n",
              "max         1.000000      20.315000      10.376800      19.353000   \n",
              "\n",
              "               var_3          var_4          var_5          var_6  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        6.796529      11.078333      -5.065317       5.408949   \n",
              "std         2.043319       1.623150       7.863267       0.866607   \n",
              "min        -0.040200       5.074800     -32.562600       2.347300   \n",
              "25%         5.254075       9.883175     -11.200350       4.767700   \n",
              "50%         6.825000      11.108250      -4.833150       5.385100   \n",
              "75%         8.324100      12.261125       0.924800       6.003000   \n",
              "max        13.188300      16.671400      17.251600       8.447700   \n",
              "\n",
              "               var_7          var_8      ...              var_190  \\\n",
              "count  200000.000000  200000.000000      ...        200000.000000   \n",
              "mean       16.545850       0.284162      ...             3.234440   \n",
              "std         3.418076       3.332634      ...             4.559922   \n",
              "min         5.349700     -10.505500      ...           -14.093300   \n",
              "25%        13.943800      -2.317800      ...            -0.058825   \n",
              "50%        16.456800       0.393700      ...             3.203600   \n",
              "75%        19.102900       2.937900      ...             6.406200   \n",
              "max        27.691800      10.151300      ...            18.440900   \n",
              "\n",
              "             var_191        var_192        var_193        var_194  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        7.438408       1.927839       3.331774      17.993784   \n",
              "std         3.023272       1.478423       3.992030       3.135162   \n",
              "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
              "25%         5.157400       0.889775       0.584600      15.629800   \n",
              "50%         7.347750       1.901300       3.396350      17.957950   \n",
              "75%         9.512525       2.949500       6.205800      20.396525   \n",
              "max        16.716500       8.402400      18.281800      27.928800   \n",
              "\n",
              "             var_195        var_196        var_197        var_198  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       -0.142088       2.303335       8.908158      15.870720   \n",
              "std         1.429372       5.454369       0.921625       3.010945   \n",
              "min        -5.261000     -14.209600       5.960600       6.299300   \n",
              "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
              "50%        -0.172700       2.408900       8.888200      15.934050   \n",
              "75%         0.829600       6.556725       9.593300      18.064725   \n",
              "max         4.272900      18.321500      12.000400      26.079100   \n",
              "\n",
              "             var_199  \n",
              "count  200000.000000  \n",
              "mean       -3.326537  \n",
              "std        10.438015  \n",
              "min       -38.852800  \n",
              "25%       -11.208475  \n",
              "50%        -2.819550  \n",
              "75%         4.836800  \n",
              "max        28.500700  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "vfI-gefMtLD5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###LGBM"
      ]
    },
    {
      "metadata": {
        "id": "q-NkiIIgxKFk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2cUzcI09tJ47",
        "colab_type": "code",
        "outputId": "81ae4527-325c-4208-862e-889f9d12a0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
        "target = train_df['target']\n",
        "print (\"Data is ready!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQ3kKKm-wSwS",
        "colab_type": "code",
        "outputId": "9f379458-fdfd-4f68-b00c-4e227488e564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.head(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>train_5</td>\n",
              "      <td>0</td>\n",
              "      <td>11.4763</td>\n",
              "      <td>-2.3182</td>\n",
              "      <td>12.6080</td>\n",
              "      <td>8.6264</td>\n",
              "      <td>10.9621</td>\n",
              "      <td>3.5609</td>\n",
              "      <td>4.5322</td>\n",
              "      <td>15.2255</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.3068</td>\n",
              "      <td>6.6025</td>\n",
              "      <td>5.2912</td>\n",
              "      <td>0.4403</td>\n",
              "      <td>14.9452</td>\n",
              "      <td>1.0314</td>\n",
              "      <td>-3.6241</td>\n",
              "      <td>9.7670</td>\n",
              "      <td>12.5809</td>\n",
              "      <td>-4.7602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>train_6</td>\n",
              "      <td>0</td>\n",
              "      <td>11.8091</td>\n",
              "      <td>-0.0832</td>\n",
              "      <td>9.3494</td>\n",
              "      <td>4.2916</td>\n",
              "      <td>11.1355</td>\n",
              "      <td>-8.0198</td>\n",
              "      <td>6.1961</td>\n",
              "      <td>12.0771</td>\n",
              "      <td>...</td>\n",
              "      <td>8.7830</td>\n",
              "      <td>6.4521</td>\n",
              "      <td>3.5325</td>\n",
              "      <td>0.1777</td>\n",
              "      <td>18.3314</td>\n",
              "      <td>0.5845</td>\n",
              "      <td>9.1104</td>\n",
              "      <td>9.1143</td>\n",
              "      <td>10.8869</td>\n",
              "      <td>-3.2097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>train_7</td>\n",
              "      <td>0</td>\n",
              "      <td>13.5580</td>\n",
              "      <td>-7.9881</td>\n",
              "      <td>13.8776</td>\n",
              "      <td>7.5985</td>\n",
              "      <td>8.6543</td>\n",
              "      <td>0.8310</td>\n",
              "      <td>5.6890</td>\n",
              "      <td>22.3262</td>\n",
              "      <td>...</td>\n",
              "      <td>13.1700</td>\n",
              "      <td>6.5491</td>\n",
              "      <td>3.9906</td>\n",
              "      <td>5.8061</td>\n",
              "      <td>23.1407</td>\n",
              "      <td>-0.3776</td>\n",
              "      <td>4.2178</td>\n",
              "      <td>9.4237</td>\n",
              "      <td>8.6624</td>\n",
              "      <td>3.4806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>train_8</td>\n",
              "      <td>0</td>\n",
              "      <td>16.1071</td>\n",
              "      <td>2.4426</td>\n",
              "      <td>13.9307</td>\n",
              "      <td>5.6327</td>\n",
              "      <td>8.8014</td>\n",
              "      <td>6.1630</td>\n",
              "      <td>4.4514</td>\n",
              "      <td>10.1854</td>\n",
              "      <td>...</td>\n",
              "      <td>1.4298</td>\n",
              "      <td>14.7510</td>\n",
              "      <td>1.6395</td>\n",
              "      <td>1.4181</td>\n",
              "      <td>14.8370</td>\n",
              "      <td>-1.9940</td>\n",
              "      <td>-1.0733</td>\n",
              "      <td>8.1975</td>\n",
              "      <td>19.5114</td>\n",
              "      <td>4.8453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>train_9</td>\n",
              "      <td>0</td>\n",
              "      <td>12.5088</td>\n",
              "      <td>1.9743</td>\n",
              "      <td>8.8960</td>\n",
              "      <td>5.4508</td>\n",
              "      <td>13.6043</td>\n",
              "      <td>-16.2859</td>\n",
              "      <td>6.0637</td>\n",
              "      <td>16.8410</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5543</td>\n",
              "      <td>6.3160</td>\n",
              "      <td>1.0371</td>\n",
              "      <td>3.6885</td>\n",
              "      <td>14.8344</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>14.1287</td>\n",
              "      <td>7.9133</td>\n",
              "      <td>16.2375</td>\n",
              "      <td>14.2514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>train_10</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0702</td>\n",
              "      <td>-0.5447</td>\n",
              "      <td>9.5900</td>\n",
              "      <td>4.2987</td>\n",
              "      <td>12.3910</td>\n",
              "      <td>-18.8687</td>\n",
              "      <td>6.0382</td>\n",
              "      <td>14.3797</td>\n",
              "      <td>...</td>\n",
              "      <td>7.2780</td>\n",
              "      <td>8.0819</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>-0.0761</td>\n",
              "      <td>14.9585</td>\n",
              "      <td>-1.2160</td>\n",
              "      <td>6.6576</td>\n",
              "      <td>9.2553</td>\n",
              "      <td>14.2914</td>\n",
              "      <td>-7.6652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>train_11</td>\n",
              "      <td>0</td>\n",
              "      <td>12.7188</td>\n",
              "      <td>-7.9750</td>\n",
              "      <td>10.3757</td>\n",
              "      <td>9.0101</td>\n",
              "      <td>12.8570</td>\n",
              "      <td>-12.0852</td>\n",
              "      <td>5.6464</td>\n",
              "      <td>11.8370</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.8901</td>\n",
              "      <td>2.6559</td>\n",
              "      <td>-0.0503</td>\n",
              "      <td>5.5946</td>\n",
              "      <td>13.6152</td>\n",
              "      <td>2.4058</td>\n",
              "      <td>-1.7183</td>\n",
              "      <td>9.6745</td>\n",
              "      <td>16.7498</td>\n",
              "      <td>-3.9728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>train_12</td>\n",
              "      <td>0</td>\n",
              "      <td>8.7671</td>\n",
              "      <td>-4.6154</td>\n",
              "      <td>9.7242</td>\n",
              "      <td>7.4242</td>\n",
              "      <td>9.0254</td>\n",
              "      <td>1.4247</td>\n",
              "      <td>6.2815</td>\n",
              "      <td>12.3143</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3782</td>\n",
              "      <td>7.4382</td>\n",
              "      <td>0.0854</td>\n",
              "      <td>1.3444</td>\n",
              "      <td>17.2439</td>\n",
              "      <td>-0.0798</td>\n",
              "      <td>5.7389</td>\n",
              "      <td>8.4897</td>\n",
              "      <td>17.0938</td>\n",
              "      <td>4.6106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>train_13</td>\n",
              "      <td>1</td>\n",
              "      <td>16.3699</td>\n",
              "      <td>1.5934</td>\n",
              "      <td>16.7395</td>\n",
              "      <td>7.3330</td>\n",
              "      <td>12.1450</td>\n",
              "      <td>5.9004</td>\n",
              "      <td>4.8222</td>\n",
              "      <td>20.9729</td>\n",
              "      <td>...</td>\n",
              "      <td>7.4002</td>\n",
              "      <td>7.4031</td>\n",
              "      <td>4.3989</td>\n",
              "      <td>4.0978</td>\n",
              "      <td>17.3638</td>\n",
              "      <td>-1.3022</td>\n",
              "      <td>9.6846</td>\n",
              "      <td>9.0419</td>\n",
              "      <td>15.6064</td>\n",
              "      <td>-10.8529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>train_14</td>\n",
              "      <td>0</td>\n",
              "      <td>13.8080</td>\n",
              "      <td>5.0514</td>\n",
              "      <td>17.2611</td>\n",
              "      <td>8.5120</td>\n",
              "      <td>12.8517</td>\n",
              "      <td>-9.1622</td>\n",
              "      <td>5.7327</td>\n",
              "      <td>21.0517</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0740</td>\n",
              "      <td>8.3220</td>\n",
              "      <td>3.2619</td>\n",
              "      <td>1.6738</td>\n",
              "      <td>17.4797</td>\n",
              "      <td>-0.0257</td>\n",
              "      <td>-3.5323</td>\n",
              "      <td>9.3439</td>\n",
              "      <td>24.4479</td>\n",
              "      <td>-5.1110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 202 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID_code  target    var_0   var_1    var_2   var_3    var_4    var_5  \\\n",
              "0    train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834   \n",
              "1    train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433   \n",
              "2    train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837   \n",
              "3    train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361   \n",
              "4    train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486   \n",
              "5    train_5       0  11.4763 -2.3182  12.6080  8.6264  10.9621   3.5609   \n",
              "6    train_6       0  11.8091 -0.0832   9.3494  4.2916  11.1355  -8.0198   \n",
              "7    train_7       0  13.5580 -7.9881  13.8776  7.5985   8.6543   0.8310   \n",
              "8    train_8       0  16.1071  2.4426  13.9307  5.6327   8.8014   6.1630   \n",
              "9    train_9       0  12.5088  1.9743   8.8960  5.4508  13.6043 -16.2859   \n",
              "10  train_10       0   5.0702 -0.5447   9.5900  4.2987  12.3910 -18.8687   \n",
              "11  train_11       0  12.7188 -7.9750  10.3757  9.0101  12.8570 -12.0852   \n",
              "12  train_12       0   8.7671 -4.6154   9.7242  7.4242   9.0254   1.4247   \n",
              "13  train_13       1  16.3699  1.5934  16.7395  7.3330  12.1450   5.9004   \n",
              "14  train_14       0  13.8080  5.0514  17.2611  8.5120  12.8517  -9.1622   \n",
              "\n",
              "     var_6    var_7   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
              "0   5.1187  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
              "1   5.6208  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
              "2   6.9427  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
              "3   5.8428  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
              "4   5.9405  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
              "5   4.5322  15.2255   ...     -6.3068   6.6025   5.2912   0.4403  14.9452   \n",
              "6   6.1961  12.0771   ...      8.7830   6.4521   3.5325   0.1777  18.3314   \n",
              "7   5.6890  22.3262   ...     13.1700   6.5491   3.9906   5.8061  23.1407   \n",
              "8   4.4514  10.1854   ...      1.4298  14.7510   1.6395   1.4181  14.8370   \n",
              "9   6.0637  16.8410   ...      0.5543   6.3160   1.0371   3.6885  14.8344   \n",
              "10  6.0382  14.3797   ...      7.2780   8.0819   0.2139  -0.0761  14.9585   \n",
              "11  5.6464  11.8370   ...     -0.8901   2.6559  -0.0503   5.5946  13.6152   \n",
              "12  6.2815  12.3143   ...      0.3782   7.4382   0.0854   1.3444  17.2439   \n",
              "13  4.8222  20.9729   ...      7.4002   7.4031   4.3989   4.0978  17.3638   \n",
              "14  5.7327  21.0517   ...      1.0740   8.3220   3.2619   1.6738  17.4797   \n",
              "\n",
              "    var_195  var_196  var_197  var_198  var_199  \n",
              "0   -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
              "1    2.0339   8.1267   8.7889  18.3560   1.9518  \n",
              "2    3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
              "3   -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
              "5    1.0314  -3.6241   9.7670  12.5809  -4.7602  \n",
              "6    0.5845   9.1104   9.1143  10.8869  -3.2097  \n",
              "7   -0.3776   4.2178   9.4237   8.6624   3.4806  \n",
              "8   -1.9940  -1.0733   8.1975  19.5114   4.8453  \n",
              "9    0.4467  14.1287   7.9133  16.2375  14.2514  \n",
              "10  -1.2160   6.6576   9.2553  14.2914  -7.6652  \n",
              "11   2.4058  -1.7183   9.6745  16.7498  -3.9728  \n",
              "12  -0.0798   5.7389   8.4897  17.0938   4.6106  \n",
              "13  -1.3022   9.6846   9.0419  15.6064 -10.8529  \n",
              "14  -0.0257  -3.5323   9.3439  24.4479  -5.1110  \n",
              "\n",
              "[15 rows x 202 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "9_ekcE-IwZB8",
        "colab_type": "code",
        "outputId": "22551252-5a2d-40e3-e817-feaec90a06db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.100490</td>\n",
              "      <td>10.679914</td>\n",
              "      <td>-1.627622</td>\n",
              "      <td>10.715192</td>\n",
              "      <td>6.796529</td>\n",
              "      <td>11.078333</td>\n",
              "      <td>-5.065317</td>\n",
              "      <td>5.408949</td>\n",
              "      <td>16.545850</td>\n",
              "      <td>0.284162</td>\n",
              "      <td>...</td>\n",
              "      <td>3.234440</td>\n",
              "      <td>7.438408</td>\n",
              "      <td>1.927839</td>\n",
              "      <td>3.331774</td>\n",
              "      <td>17.993784</td>\n",
              "      <td>-0.142088</td>\n",
              "      <td>2.303335</td>\n",
              "      <td>8.908158</td>\n",
              "      <td>15.870720</td>\n",
              "      <td>-3.326537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.300653</td>\n",
              "      <td>3.040051</td>\n",
              "      <td>4.050044</td>\n",
              "      <td>2.640894</td>\n",
              "      <td>2.043319</td>\n",
              "      <td>1.623150</td>\n",
              "      <td>7.863267</td>\n",
              "      <td>0.866607</td>\n",
              "      <td>3.418076</td>\n",
              "      <td>3.332634</td>\n",
              "      <td>...</td>\n",
              "      <td>4.559922</td>\n",
              "      <td>3.023272</td>\n",
              "      <td>1.478423</td>\n",
              "      <td>3.992030</td>\n",
              "      <td>3.135162</td>\n",
              "      <td>1.429372</td>\n",
              "      <td>5.454369</td>\n",
              "      <td>0.921625</td>\n",
              "      <td>3.010945</td>\n",
              "      <td>10.438015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.453850</td>\n",
              "      <td>-4.740025</td>\n",
              "      <td>8.722475</td>\n",
              "      <td>5.254075</td>\n",
              "      <td>9.883175</td>\n",
              "      <td>-11.200350</td>\n",
              "      <td>4.767700</td>\n",
              "      <td>13.943800</td>\n",
              "      <td>-2.317800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058825</td>\n",
              "      <td>5.157400</td>\n",
              "      <td>0.889775</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>15.629800</td>\n",
              "      <td>-1.170700</td>\n",
              "      <td>-1.946925</td>\n",
              "      <td>8.252800</td>\n",
              "      <td>13.829700</td>\n",
              "      <td>-11.208475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.524750</td>\n",
              "      <td>-1.608050</td>\n",
              "      <td>10.580000</td>\n",
              "      <td>6.825000</td>\n",
              "      <td>11.108250</td>\n",
              "      <td>-4.833150</td>\n",
              "      <td>5.385100</td>\n",
              "      <td>16.456800</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.203600</td>\n",
              "      <td>7.347750</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>3.396350</td>\n",
              "      <td>17.957950</td>\n",
              "      <td>-0.172700</td>\n",
              "      <td>2.408900</td>\n",
              "      <td>8.888200</td>\n",
              "      <td>15.934050</td>\n",
              "      <td>-2.819550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.758200</td>\n",
              "      <td>1.358625</td>\n",
              "      <td>12.516700</td>\n",
              "      <td>8.324100</td>\n",
              "      <td>12.261125</td>\n",
              "      <td>0.924800</td>\n",
              "      <td>6.003000</td>\n",
              "      <td>19.102900</td>\n",
              "      <td>2.937900</td>\n",
              "      <td>...</td>\n",
              "      <td>6.406200</td>\n",
              "      <td>9.512525</td>\n",
              "      <td>2.949500</td>\n",
              "      <td>6.205800</td>\n",
              "      <td>20.396525</td>\n",
              "      <td>0.829600</td>\n",
              "      <td>6.556725</td>\n",
              "      <td>9.593300</td>\n",
              "      <td>18.064725</td>\n",
              "      <td>4.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              target          var_0          var_1          var_2  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        0.100490      10.679914      -1.627622      10.715192   \n",
              "std         0.300653       3.040051       4.050044       2.640894   \n",
              "min         0.000000       0.408400     -15.043400       2.117100   \n",
              "25%         0.000000       8.453850      -4.740025       8.722475   \n",
              "50%         0.000000      10.524750      -1.608050      10.580000   \n",
              "75%         0.000000      12.758200       1.358625      12.516700   \n",
              "max         1.000000      20.315000      10.376800      19.353000   \n",
              "\n",
              "               var_3          var_4          var_5          var_6  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        6.796529      11.078333      -5.065317       5.408949   \n",
              "std         2.043319       1.623150       7.863267       0.866607   \n",
              "min        -0.040200       5.074800     -32.562600       2.347300   \n",
              "25%         5.254075       9.883175     -11.200350       4.767700   \n",
              "50%         6.825000      11.108250      -4.833150       5.385100   \n",
              "75%         8.324100      12.261125       0.924800       6.003000   \n",
              "max        13.188300      16.671400      17.251600       8.447700   \n",
              "\n",
              "               var_7          var_8      ...              var_190  \\\n",
              "count  200000.000000  200000.000000      ...        200000.000000   \n",
              "mean       16.545850       0.284162      ...             3.234440   \n",
              "std         3.418076       3.332634      ...             4.559922   \n",
              "min         5.349700     -10.505500      ...           -14.093300   \n",
              "25%        13.943800      -2.317800      ...            -0.058825   \n",
              "50%        16.456800       0.393700      ...             3.203600   \n",
              "75%        19.102900       2.937900      ...             6.406200   \n",
              "max        27.691800      10.151300      ...            18.440900   \n",
              "\n",
              "             var_191        var_192        var_193        var_194  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean        7.438408       1.927839       3.331774      17.993784   \n",
              "std         3.023272       1.478423       3.992030       3.135162   \n",
              "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
              "25%         5.157400       0.889775       0.584600      15.629800   \n",
              "50%         7.347750       1.901300       3.396350      17.957950   \n",
              "75%         9.512525       2.949500       6.205800      20.396525   \n",
              "max        16.716500       8.402400      18.281800      27.928800   \n",
              "\n",
              "             var_195        var_196        var_197        var_198  \\\n",
              "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
              "mean       -0.142088       2.303335       8.908158      15.870720   \n",
              "std         1.429372       5.454369       0.921625       3.010945   \n",
              "min        -5.261000     -14.209600       5.960600       6.299300   \n",
              "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
              "50%        -0.172700       2.408900       8.888200      15.934050   \n",
              "75%         0.829600       6.556725       9.593300      18.064725   \n",
              "max         4.272900      18.321500      12.000400      26.079100   \n",
              "\n",
              "             var_199  \n",
              "count  200000.000000  \n",
              "mean       -3.326537  \n",
              "std        10.438015  \n",
              "min       -38.852800  \n",
              "25%       -11.208475  \n",
              "50%        -2.819550  \n",
              "75%         4.836800  \n",
              "max        28.500700  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Jri9DCV8wcOX",
        "colab_type": "code",
        "outputId": "42aa8ed0-d094-4b1e-e7aa-ce713ce296c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "train_df[train_df['target']==0].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>179902.0</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "      <td>179902.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.626681</td>\n",
              "      <td>-1.695770</td>\n",
              "      <td>10.665876</td>\n",
              "      <td>6.788979</td>\n",
              "      <td>11.072412</td>\n",
              "      <td>-5.146736</td>\n",
              "      <td>5.389620</td>\n",
              "      <td>16.549306</td>\n",
              "      <td>0.262347</td>\n",
              "      <td>...</td>\n",
              "      <td>3.149130</td>\n",
              "      <td>7.390800</td>\n",
              "      <td>1.949017</td>\n",
              "      <td>3.355403</td>\n",
              "      <td>18.017716</td>\n",
              "      <td>-0.155601</td>\n",
              "      <td>2.260297</td>\n",
              "      <td>8.919032</td>\n",
              "      <td>15.924058</td>\n",
              "      <td>-3.415273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.008564</td>\n",
              "      <td>4.024813</td>\n",
              "      <td>2.612961</td>\n",
              "      <td>2.040082</td>\n",
              "      <td>1.620103</td>\n",
              "      <td>7.827522</td>\n",
              "      <td>0.857983</td>\n",
              "      <td>3.417700</td>\n",
              "      <td>3.331105</td>\n",
              "      <td>...</td>\n",
              "      <td>4.522568</td>\n",
              "      <td>2.997847</td>\n",
              "      <td>1.476456</td>\n",
              "      <td>3.982819</td>\n",
              "      <td>3.127715</td>\n",
              "      <td>1.422275</td>\n",
              "      <td>5.441118</td>\n",
              "      <td>0.917467</td>\n",
              "      <td>2.978539</td>\n",
              "      <td>10.434525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408400</td>\n",
              "      <td>-15.043400</td>\n",
              "      <td>2.117100</td>\n",
              "      <td>-0.040200</td>\n",
              "      <td>5.074800</td>\n",
              "      <td>-32.562600</td>\n",
              "      <td>2.347300</td>\n",
              "      <td>5.349700</td>\n",
              "      <td>-10.505500</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.093300</td>\n",
              "      <td>-2.691700</td>\n",
              "      <td>-3.814500</td>\n",
              "      <td>-10.845500</td>\n",
              "      <td>8.694400</td>\n",
              "      <td>-5.261000</td>\n",
              "      <td>-14.209600</td>\n",
              "      <td>5.960600</td>\n",
              "      <td>6.299300</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.429500</td>\n",
              "      <td>-4.790775</td>\n",
              "      <td>8.698025</td>\n",
              "      <td>5.247625</td>\n",
              "      <td>9.880600</td>\n",
              "      <td>-11.260950</td>\n",
              "      <td>4.756425</td>\n",
              "      <td>13.950125</td>\n",
              "      <td>-2.342575</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.111850</td>\n",
              "      <td>5.130825</td>\n",
              "      <td>0.915300</td>\n",
              "      <td>0.612400</td>\n",
              "      <td>15.656700</td>\n",
              "      <td>-1.178700</td>\n",
              "      <td>-1.987375</td>\n",
              "      <td>8.262100</td>\n",
              "      <td>13.896000</td>\n",
              "      <td>-11.312025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.478600</td>\n",
              "      <td>-1.682600</td>\n",
              "      <td>10.529000</td>\n",
              "      <td>6.817000</td>\n",
              "      <td>11.104400</td>\n",
              "      <td>-4.917700</td>\n",
              "      <td>5.364400</td>\n",
              "      <td>16.460850</td>\n",
              "      <td>0.371400</td>\n",
              "      <td>...</td>\n",
              "      <td>3.117250</td>\n",
              "      <td>7.297000</td>\n",
              "      <td>1.928950</td>\n",
              "      <td>3.417550</td>\n",
              "      <td>17.982400</td>\n",
              "      <td>-0.184200</td>\n",
              "      <td>2.359700</td>\n",
              "      <td>8.897700</td>\n",
              "      <td>15.988500</td>\n",
              "      <td>-2.914000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>12.693075</td>\n",
              "      <td>1.287700</td>\n",
              "      <td>12.463900</td>\n",
              "      <td>8.317875</td>\n",
              "      <td>12.253100</td>\n",
              "      <td>0.844600</td>\n",
              "      <td>5.981300</td>\n",
              "      <td>19.108800</td>\n",
              "      <td>2.919300</td>\n",
              "      <td>...</td>\n",
              "      <td>6.296375</td>\n",
              "      <td>9.461300</td>\n",
              "      <td>2.969800</td>\n",
              "      <td>6.217075</td>\n",
              "      <td>20.417500</td>\n",
              "      <td>0.813000</td>\n",
              "      <td>6.513425</td>\n",
              "      <td>9.601500</td>\n",
              "      <td>18.095400</td>\n",
              "      <td>4.741400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>20.315000</td>\n",
              "      <td>10.376800</td>\n",
              "      <td>19.353000</td>\n",
              "      <td>13.188300</td>\n",
              "      <td>16.671400</td>\n",
              "      <td>17.251600</td>\n",
              "      <td>8.447700</td>\n",
              "      <td>27.691800</td>\n",
              "      <td>10.151300</td>\n",
              "      <td>...</td>\n",
              "      <td>18.440900</td>\n",
              "      <td>16.716500</td>\n",
              "      <td>8.402400</td>\n",
              "      <td>18.281800</td>\n",
              "      <td>27.928800</td>\n",
              "      <td>4.272900</td>\n",
              "      <td>18.321500</td>\n",
              "      <td>12.000400</td>\n",
              "      <td>26.079100</td>\n",
              "      <td>28.500700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target          var_0          var_1          var_2          var_3  \\\n",
              "count  179902.0  179902.000000  179902.000000  179902.000000  179902.000000   \n",
              "mean        0.0      10.626681      -1.695770      10.665876       6.788979   \n",
              "std         0.0       3.008564       4.024813       2.612961       2.040082   \n",
              "min         0.0       0.408400     -15.043400       2.117100      -0.040200   \n",
              "25%         0.0       8.429500      -4.790775       8.698025       5.247625   \n",
              "50%         0.0      10.478600      -1.682600      10.529000       6.817000   \n",
              "75%         0.0      12.693075       1.287700      12.463900       8.317875   \n",
              "max         0.0      20.315000      10.376800      19.353000      13.188300   \n",
              "\n",
              "               var_4          var_5          var_6          var_7  \\\n",
              "count  179902.000000  179902.000000  179902.000000  179902.000000   \n",
              "mean       11.072412      -5.146736       5.389620      16.549306   \n",
              "std         1.620103       7.827522       0.857983       3.417700   \n",
              "min         5.074800     -32.562600       2.347300       5.349700   \n",
              "25%         9.880600     -11.260950       4.756425      13.950125   \n",
              "50%        11.104400      -4.917700       5.364400      16.460850   \n",
              "75%        12.253100       0.844600       5.981300      19.108800   \n",
              "max        16.671400      17.251600       8.447700      27.691800   \n",
              "\n",
              "               var_8      ...              var_190        var_191  \\\n",
              "count  179902.000000      ...        179902.000000  179902.000000   \n",
              "mean        0.262347      ...             3.149130       7.390800   \n",
              "std         3.331105      ...             4.522568       2.997847   \n",
              "min       -10.505500      ...           -14.093300      -2.691700   \n",
              "25%        -2.342575      ...            -0.111850       5.130825   \n",
              "50%         0.371400      ...             3.117250       7.297000   \n",
              "75%         2.919300      ...             6.296375       9.461300   \n",
              "max        10.151300      ...            18.440900      16.716500   \n",
              "\n",
              "             var_192        var_193        var_194        var_195  \\\n",
              "count  179902.000000  179902.000000  179902.000000  179902.000000   \n",
              "mean        1.949017       3.355403      18.017716      -0.155601   \n",
              "std         1.476456       3.982819       3.127715       1.422275   \n",
              "min        -3.814500     -10.845500       8.694400      -5.261000   \n",
              "25%         0.915300       0.612400      15.656700      -1.178700   \n",
              "50%         1.928950       3.417550      17.982400      -0.184200   \n",
              "75%         2.969800       6.217075      20.417500       0.813000   \n",
              "max         8.402400      18.281800      27.928800       4.272900   \n",
              "\n",
              "             var_196        var_197        var_198        var_199  \n",
              "count  179902.000000  179902.000000  179902.000000  179902.000000  \n",
              "mean        2.260297       8.919032      15.924058      -3.415273  \n",
              "std         5.441118       0.917467       2.978539      10.434525  \n",
              "min       -14.209600       5.960600       6.299300     -38.852800  \n",
              "25%        -1.987375       8.262100      13.896000     -11.312025  \n",
              "50%         2.359700       8.897700      15.988500      -2.914000  \n",
              "75%         6.513425       9.601500      18.095400       4.741400  \n",
              "max        18.321500      12.000400      26.079100      28.500700  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "0lK_qjHMwiQH",
        "colab_type": "code",
        "outputId": "70cbd510-3c2d-4d4c-a51d-7118c7857cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "cell_type": "code",
      "source": [
        "train_df[train_df['target']==1].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>var_8</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20098.0</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "      <td>20098.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.156418</td>\n",
              "      <td>-1.017613</td>\n",
              "      <td>11.156633</td>\n",
              "      <td>6.864113</td>\n",
              "      <td>11.131337</td>\n",
              "      <td>-4.336522</td>\n",
              "      <td>5.581966</td>\n",
              "      <td>16.514917</td>\n",
              "      <td>0.479432</td>\n",
              "      <td>...</td>\n",
              "      <td>3.998064</td>\n",
              "      <td>7.864560</td>\n",
              "      <td>1.738266</td>\n",
              "      <td>3.120260</td>\n",
              "      <td>17.779568</td>\n",
              "      <td>-0.021130</td>\n",
              "      <td>2.688583</td>\n",
              "      <td>8.810815</td>\n",
              "      <td>15.393283</td>\n",
              "      <td>-2.532243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.270293</td>\n",
              "      <td>4.220638</td>\n",
              "      <td>2.841075</td>\n",
              "      <td>2.070898</td>\n",
              "      <td>1.649266</td>\n",
              "      <td>8.140281</td>\n",
              "      <td>0.922442</td>\n",
              "      <td>3.421365</td>\n",
              "      <td>3.340028</td>\n",
              "      <td>...</td>\n",
              "      <td>4.814830</td>\n",
              "      <td>3.210779</td>\n",
              "      <td>1.482537</td>\n",
              "      <td>4.067550</td>\n",
              "      <td>3.193153</td>\n",
              "      <td>1.485975</td>\n",
              "      <td>5.556892</td>\n",
              "      <td>0.952554</td>\n",
              "      <td>3.248123</td>\n",
              "      <td>10.435910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.452800</td>\n",
              "      <td>-14.037000</td>\n",
              "      <td>2.946200</td>\n",
              "      <td>0.374000</td>\n",
              "      <td>5.876200</td>\n",
              "      <td>-28.246100</td>\n",
              "      <td>2.496000</td>\n",
              "      <td>7.302400</td>\n",
              "      <td>-9.839100</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.906900</td>\n",
              "      <td>-2.343000</td>\n",
              "      <td>-3.317700</td>\n",
              "      <td>-11.783400</td>\n",
              "      <td>10.120700</td>\n",
              "      <td>-5.018500</td>\n",
              "      <td>-14.020400</td>\n",
              "      <td>6.119000</td>\n",
              "      <td>6.558700</td>\n",
              "      <td>-38.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8.695875</td>\n",
              "      <td>-4.203475</td>\n",
              "      <td>8.961125</td>\n",
              "      <td>5.314300</td>\n",
              "      <td>9.911250</td>\n",
              "      <td>-10.615800</td>\n",
              "      <td>4.882250</td>\n",
              "      <td>13.880125</td>\n",
              "      <td>-2.107425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.466025</td>\n",
              "      <td>5.418550</td>\n",
              "      <td>0.669775</td>\n",
              "      <td>0.343000</td>\n",
              "      <td>15.420025</td>\n",
              "      <td>-1.103950</td>\n",
              "      <td>-1.572225</td>\n",
              "      <td>8.155250</td>\n",
              "      <td>13.232500</td>\n",
              "      <td>-10.285050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.001350</td>\n",
              "      <td>-0.992650</td>\n",
              "      <td>11.096700</td>\n",
              "      <td>6.900200</td>\n",
              "      <td>11.156300</td>\n",
              "      <td>-4.101950</td>\n",
              "      <td>5.601800</td>\n",
              "      <td>16.412700</td>\n",
              "      <td>0.579600</td>\n",
              "      <td>...</td>\n",
              "      <td>4.017500</td>\n",
              "      <td>7.846550</td>\n",
              "      <td>1.667500</td>\n",
              "      <td>3.176700</td>\n",
              "      <td>17.730500</td>\n",
              "      <td>-0.057350</td>\n",
              "      <td>2.831050</td>\n",
              "      <td>8.795400</td>\n",
              "      <td>15.427950</td>\n",
              "      <td>-1.971850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>13.343700</td>\n",
              "      <td>2.001375</td>\n",
              "      <td>13.047025</td>\n",
              "      <td>8.384725</td>\n",
              "      <td>12.328450</td>\n",
              "      <td>1.619950</td>\n",
              "      <td>6.218550</td>\n",
              "      <td>19.044250</td>\n",
              "      <td>3.127825</td>\n",
              "      <td>...</td>\n",
              "      <td>7.407925</td>\n",
              "      <td>10.018400</td>\n",
              "      <td>2.749050</td>\n",
              "      <td>6.063825</td>\n",
              "      <td>20.201800</td>\n",
              "      <td>0.986450</td>\n",
              "      <td>6.956250</td>\n",
              "      <td>9.517000</td>\n",
              "      <td>17.776425</td>\n",
              "      <td>5.701475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>19.458300</td>\n",
              "      <td>9.029800</td>\n",
              "      <td>18.294100</td>\n",
              "      <td>12.706900</td>\n",
              "      <td>15.692500</td>\n",
              "      <td>16.423600</td>\n",
              "      <td>8.285200</td>\n",
              "      <td>27.039800</td>\n",
              "      <td>9.033000</td>\n",
              "      <td>...</td>\n",
              "      <td>16.746100</td>\n",
              "      <td>16.520500</td>\n",
              "      <td>7.647600</td>\n",
              "      <td>17.150400</td>\n",
              "      <td>27.295300</td>\n",
              "      <td>4.088100</td>\n",
              "      <td>17.161400</td>\n",
              "      <td>11.706900</td>\n",
              "      <td>25.857100</td>\n",
              "      <td>24.564600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target         var_0         var_1         var_2         var_3  \\\n",
              "count  20098.0  20098.000000  20098.000000  20098.000000  20098.000000   \n",
              "mean       1.0     11.156418     -1.017613     11.156633      6.864113   \n",
              "std        0.0      3.270293      4.220638      2.841075      2.070898   \n",
              "min        1.0      0.452800    -14.037000      2.946200      0.374000   \n",
              "25%        1.0      8.695875     -4.203475      8.961125      5.314300   \n",
              "50%        1.0     11.001350     -0.992650     11.096700      6.900200   \n",
              "75%        1.0     13.343700      2.001375     13.047025      8.384725   \n",
              "max        1.0     19.458300      9.029800     18.294100     12.706900   \n",
              "\n",
              "              var_4         var_5         var_6         var_7         var_8  \\\n",
              "count  20098.000000  20098.000000  20098.000000  20098.000000  20098.000000   \n",
              "mean      11.131337     -4.336522      5.581966     16.514917      0.479432   \n",
              "std        1.649266      8.140281      0.922442      3.421365      3.340028   \n",
              "min        5.876200    -28.246100      2.496000      7.302400     -9.839100   \n",
              "25%        9.911250    -10.615800      4.882250     13.880125     -2.107425   \n",
              "50%       11.156300     -4.101950      5.601800     16.412700      0.579600   \n",
              "75%       12.328450      1.619950      6.218550     19.044250      3.127825   \n",
              "max       15.692500     16.423600      8.285200     27.039800      9.033000   \n",
              "\n",
              "           ...            var_190       var_191       var_192       var_193  \\\n",
              "count      ...       20098.000000  20098.000000  20098.000000  20098.000000   \n",
              "mean       ...           3.998064      7.864560      1.738266      3.120260   \n",
              "std        ...           4.814830      3.210779      1.482537      4.067550   \n",
              "min        ...         -11.906900     -2.343000     -3.317700    -11.783400   \n",
              "25%        ...           0.466025      5.418550      0.669775      0.343000   \n",
              "50%        ...           4.017500      7.846550      1.667500      3.176700   \n",
              "75%        ...           7.407925     10.018400      2.749050      6.063825   \n",
              "max        ...          16.746100     16.520500      7.647600     17.150400   \n",
              "\n",
              "            var_194       var_195       var_196       var_197       var_198  \\\n",
              "count  20098.000000  20098.000000  20098.000000  20098.000000  20098.000000   \n",
              "mean      17.779568     -0.021130      2.688583      8.810815     15.393283   \n",
              "std        3.193153      1.485975      5.556892      0.952554      3.248123   \n",
              "min       10.120700     -5.018500    -14.020400      6.119000      6.558700   \n",
              "25%       15.420025     -1.103950     -1.572225      8.155250     13.232500   \n",
              "50%       17.730500     -0.057350      2.831050      8.795400     15.427950   \n",
              "75%       20.201800      0.986450      6.956250      9.517000     17.776425   \n",
              "max       27.295300      4.088100     17.161400     11.706900     25.857100   \n",
              "\n",
              "            var_199  \n",
              "count  20098.000000  \n",
              "mean      -2.532243  \n",
              "std       10.435910  \n",
              "min      -38.852800  \n",
              "25%      -10.285050  \n",
              "50%       -1.971850  \n",
              "75%        5.701475  \n",
              "max       24.564600  \n",
              "\n",
              "[8 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "kY_Q87uOwnQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop([\"target\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UOhHKa0JwtOt",
        "colab_type": "code",
        "outputId": "5be46db1-35b0-4586-d6d4-15d7f55189a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(target)\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFYCAYAAADOev/+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X9Q1VXi//HX+3K5IQnhJa6Z/VhN\nU7eEEjYVIhdXqnWqtRJDwsbP2myOP7KNMrufUlw1/LG0rmWzhWWmkUy2s8s0LjgVOlteKS+TP9pY\nstqGpV24t5UEsQHhfv/o2/0sq0vYcu9dOM/HTDNxeN9zz3HmDk/e73vfWIFAICAAAGAsW6QXAAAA\nIosYAADAcMQAAACGIwYAADAcMQAAgOGIAQAADGeP9AIixev1RnoJAACEVWpq6lnHjY0B6d//owAA\nMND09EswlwkAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEA\nAIDhiAEAAAxHDAAAYDij/1BRKOQtfTnSSwD6ROn6uyO9BABhwpkBAAAMRwwAAGA4YgAAAMOF9D0D\ndXV1WrBggebOnav8/Hzdf//9On78uCSpublZ11xzje677z7deuutuvrqqyVJQ4YM0aZNm9TS0qKC\nggK1tLQoNjZWxcXFSkhI0P79+/Xkk08qKipKN9xwgxYuXChJeuKJJ3To0CFZliW3263k5ORQbg0A\ngAEjZDHQ1tamVatWafLkycGxTZs2Bf//0UcfVU5OjiRpxIgR2r59e7fHb9u2Tdddd53uvfdelZWV\nqaSkRA8//LBWr16t559/XkOHDlV+fr5uuukm/eMf/9Bnn32msrIyffzxx3K73SorKwvV1gAAGFBC\ndpnA4XCopKRELpfrjO998sknamlp6fG3d4/Ho+zsbElSVlaWPB6P6uvrdcEFF2jYsGGy2WyaMmWK\nPB6PPB6Ppk2bJkm64oor9OWXX6q1tTU0GwMAYIAJWQzY7XbFxMSc9XsvvfSS8vPzg1/7/X7df//9\nys3NVXl5eXDM6XRKkhITE9XU1CSfzxcckySn0ymfzye/368hQ4acMQ4AAL5d2O8z0N7eLq/Xq8LC\nQklSQkKClixZottuu00tLS3KycnRpEmTuj0mEAic03P09niv13tO8wIm4fUBmCPsMfDee+91uzww\nePBg3XnnnZK+/o3+6quv1ieffCKXyyWfz6e4uDg1NjbK5XLJ5XLJ7/cHH/vNeHR0dLfxpqYmJSUl\nfetaUlNT+3Bn/19Zbd/PCURASF4fACKmp8AP+0cLjxw5orFjxwa/PnDggIqKiiR9/abD2tpajRgx\nQhkZGaqoqJAk7dmzR5mZmbrkkkvU2tqqv/71rzp9+rSqqqqUkZGhjIwMVVZWSpI++OADuVwuDR48\nONxbAwCgXwrZmYGjR49q3bp1amhokN1uV2VlpZ566in5fD5ddtllwePS0tL0u9/9TnfddZc6Ozv1\ns5/9TEOHDtWcOXP08MMPKy8vT/Hx8dqwYYMkqbCwUAUFBZKk6dOna8SIERoxYoSuuuoq5ebmyrIs\nrVixIlTbAgBgwLEC53pBfoDwer0hOQ3K3ybAQMHfJgAGlp5+7nEHQgAADEcMAABgOGIAAADDEQMA\nABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYjhgAAMBwxAAAAIYj\nBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAAgOGIAQAA\nDEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwXEhjoK6uTtOmTdOOHTskScuWLdOtt96q\nOXPmaM6cOdq7d68kqby8XHfeeadycnL06quvSpI6OjpUUFCg2bNnKz8/X/X19ZKk2tpa5ebmKjc3\nVytWrAg+15YtWzRz5kzl5ORo3759odwWAAADij1UE7e1tWnVqlWaPHlyt/EHH3xQWVlZ3Y7bvHmz\ndu3apejoaM2cOVPZ2dmqqqpSfHy8iouL9fbbb6u4uFgbN27UmjVr5Ha7lZycrIKCAu3bt08jR47U\n7t27tXPnTrW2tiovL0/XX3+9oqKiQrU9AAAGjJCdGXA4HCopKZHL5erxuEOHDmn8+PGKi4tTTEyM\nJkyYoJqaGnk8HmVnZ0uS0tPTVVNTo/b2djU0NCg5OVmSlJWVJY/Ho+rqamVmZsrhcMjpdGr48OE6\nduxYqLYGAMCAErIzA3a7XXb7mdPv2LFDW7duVWJioh5//HH5/X45nc7g951Op3w+X7dxm80my7Lk\n9/sVHx8fPDYxMVE+n08JCQlnnWPMmDE9rtHr9f6n2wQGLF4fgDlCFgNn85Of/EQJCQkaN26cnnvu\nOT399NO69tprux0TCATO+tizjZ/LsWeTmpraq+POSVlt388JREBIXh8AIqanwA/rpwkmT56scePG\nSZKmTp2quro6uVwu+f3+4DFNTU1yuVxyuVzy+XySvn4zYSAQUFJSkpqbm4PHNjY2Bo/95zm+GQcA\nAN8urDGwePHi4KcCqqurNXr0aKWkpOjIkSM6ceKETp48qZqaGqWlpSkjI0MVFRWSpKqqKk2cOFHR\n0dEaOXKkDh48KEnas2ePMjMzNWnSJO3du1ft7e1qbGxUU1OTRo0aFc6tAQDQb4XsMsHRo0e1bt06\nNTQ0yG63q7KyUvn5+XrggQc0aNAgxcbGqqioSDExMSooKNC8efNkWZYWLlyouLg4TZ8+Xfv379fs\n2bPlcDi0du1aSZLb7dby5cvV1dWllJQUpaenS5JmzZql/Px8WZalwsJC2WzcQgEAgN6wAr29wD7A\neL3ekFwTzVv6cp/PCURC6fq7I70EAH2op597/PoMAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYjhgA\nAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAc\nMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAA\nYDhiAAAAwxEDAAAYjhgAAMBw9lBOXldXpwULFmju3LnKz8/X3/72Nz366KM6ffq07Ha7NmzYoKSk\nJF111VWaMGFC8HEvvviiurq6tGzZMn3++eeKiopSUVGRLr30UtXW1qqwsFCSNGbMGK1cuVKStGXL\nFlVUVMiyLC1atEhTpkwJ5dYAABgwQnZmoK2tTatWrdLkyZODYxs3btSsWbO0Y8cOZWdna+vWrZKk\nwYMHa/v27cH/oqKi9Prrrys+Pl6vvPKK5s+fr+LiYknSmjVr5Ha7tXPnTrW2tmrfvn2qr6/X7t27\nVVpaqmeffVZFRUXq7OwM1dYAABhQQhYDDodDJSUlcrlcwbEVK1bopptukiQNGTJEzc3N//bxHo9H\n2dnZkqT09HTV1NSovb1dDQ0NSk5OliRlZWXJ4/GourpamZmZcjgccjqdGj58uI4dOxaqrQEAMKCE\nLAbsdrtiYmK6jcXGxioqKkqdnZ0qLS3VrbfeKklqb29XQUGBcnNzg2cL/H6/nE7n14u02WRZlvx+\nv+Lj44PzJSYmyufzdTtWkpxOp3w+X6i2BgDAgBLS9wycTWdnp5YuXapJkyYFLyEsXbpUt912myzL\nUn5+vtLS0s54XCAQ6NVYT+P/yuv1nsPKAbPw+gDMEfYYePTRR3X55Zdr0aJFwbHZs2cH/3/SpEmq\nq6uTy+WSz+fT2LFj1dHRoUAgoKSkpG6XFhobG+VyueRyufTpp5+eMf5tUlNT+2hX/6Sstu/nBCIg\nJK8PABHTU+CH9aOF5eXlio6O1v333x8c++STT1RQUKBAIKDTp0+rpqZGo0ePVkZGhioqKiRJVVVV\nmjhxoqKjozVy5EgdPHhQkrRnzx5lZmZq0qRJ2rt3r9rb29XY2KimpiaNGjUqnFsDAKDfCtmZgaNH\nj2rdunVqaGiQ3W5XZWWlvvjiC5133nmaM2eOJOmKK65QYWGhLrroIs2cOVM2m01Tp05VcnKyrrrq\nKu3fv1+zZ8+Ww+HQ2rVrJUlut1vLly9XV1eXUlJSlJ6eLkmaNWuW8vPzZVmWCgsLZbNxCwUAAHrD\nCvT2AvsA4/V6Q3IaNG/py30+JxAJpevvjvQSAPShnn7u8eszAACGIwYAADAcMQAAgOGIAQAADEcM\nAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAY\njhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYA\nADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABgupDFQV1enadOmaceOHZKkv/3tb5ozZ47y8vK0\nZMkStbe3S5LKy8t15513KicnR6+++qokqaOjQwUFBZo9e7by8/NVX18vSaqtrVVubq5yc3O1YsWK\n4HNt2bJFM2fOVE5Ojvbt2xfKbQEAMKD0KgaWLVt2xti8efN6fExbW5tWrVqlyZMnB8c2bdqkvLw8\nlZaW6vLLL9euXbvU1tamzZs368UXX9T27du1bds2NTc36/XXX1d8fLxeeeUVzZ8/X8XFxZKkNWvW\nyO12a+fOnWptbdW+fftUX1+v3bt3q7S0VM8++6yKiorU2dl5Lv8OAAAYy97TN8vLy7Vz50599NFH\nuvvuu4PjHR0d8vv9PU7scDhUUlKikpKS4Fh1dbVWrlwpScrKytILL7ygESNGaPz48YqLi5MkTZgw\nQTU1NfJ4PJoxY4YkKT09XW63W+3t7WpoaFBycnJwDo/HI5/Pp8zMTDkcDjmdTg0fPlzHjh3TmDFj\nvsM/CQAAZukxBm677TZNnDhRDz30kBYvXhwct9lsGjVqVM8T2+2y27tPf+rUKTkcDklSYmKifD6f\n/H6/nE5n8Bin03nGuM1mk2VZ8vv9io+PDx77zRwJCQlnnYMYAADg2/UYA5I0dOhQbd++XS0tLWpu\nbg6Ot7S0KCEh4Ts/cSAQ+I/Hz3WOf+X1ent1HGAiXh+AOb41BiRp9erVeu211+R0OoM/aC3L0ptv\nvnlOTxYbG6uvvvpKMTExamxslMvlksvl6nbJoampSddcc41cLpd8Pp/Gjh2rjo4OBQIBJSUldQuS\nf57j008/PWP826Smpp7T+nulrLbv5wQiICSvDwAR01Pg9+oNhNXV1Tpw4IDefPNNvfXWW3rrrbfO\nOQSkr6/9V1ZWSpL27NmjzMxMpaSk6MiRIzpx4oROnjypmpoapaWlKSMjQxUVFZKkqqoqTZw4UdHR\n0Ro5cqQOHjzYbY5JkyZp7969am9vV2Njo5qamr71MgYAAPhar84MXH755TrvvPPOaeKjR49q3bp1\namhokN1uV2VlpX75y19q2bJlKisr08UXX6wZM2YoOjpaBQUFmjdvnizL0sKFCxUXF6fp06dr//79\nmj17thwOh9auXStJcrvdWr58ubq6upSSkqL09HRJ0qxZs5Sfny/LslRYWCibjVsoAADQG1agFxfY\nV69erQ8//FCpqamKiooKji9ZsiSkiwslr9cbktOgeUtf7vM5gUgoXX/3tx8EoN/o6eder84MJCQk\ndLtfAAAAGDh6FQMLFiwI9ToAAECE9CoGvv/978uyrODXlmUpLi5O1dXVIVsYAAAIj17FQG3t/31c\nrr29XR6PR3/+859DtigAABA+5/yWe4fDoSlTpuidd94JxXoAAECY9erMwK5du7p9/fe//12NjY0h\nWRAAAAivXsXAv961aPDgwdq4cWNIFgQAAMKrVzFQVFQkSWpubpZlWbrgggtCuigAABA+vYqBmpoa\nLV26VCdPnlQgEFBCQoI2bNig8ePHh3p9AAAgxHoVA8XFxXrmmWd05ZVXSpL+9Kc/ac2aNXr5Ze62\nBwBAf9erTxPYbLZgCEhf33fgn29LDAAA+q9ex0BlZaVaW1vV2tqq3bt3EwMAAAwQvbpMsHLlSq1a\ntUqPPfaYbDabxo4dq9WrV4d6bQAAIAx6dWbgnXfekcPh0Hvvvafq6moFAgHt27cv1GsDAABh0KsY\nKC8v19NPPx38+oUXXtDrr78eskUBAIDw6VUMdHZ2dnuPgGVZCgQCIVsUAAAIn169Z2Dq1KnKzc1V\namqqurq6dODAAd14442hXhsAAAiDXsXAggULdN111+nw4cOyLEsrVqzQNddcE+q1AQCAMOhVDEhS\nWlqa0tLSQrkWAAAQAef8J4wBAMDAQgwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAA\ngOGIAQAADEcMAABgOGIAAADD9fpvE/SFV199VeXl5cGvjx49qquvvlptbW2KjY2VJD3yyCO6+uqr\ntWXLFlVUVMiyLC1atEhTpkxRS0uLCgoK1NLSotjYWBUXFyshIUH79+/Xk08+qaioKN1www1auHBh\nOLcFAEC/FtYYyMnJUU5OjiTp3Xff1R/+8AcdO3ZMRUVFuvLKK4PH1dfXa/fu3dq5c6daW1uVl5en\n66+/Xtu2bdN1112ne++9V2VlZSopKdHDDz+s1atX6/nnn9fQoUOVn5+vm266SaNGjQrn1gAA6Lci\ndplg8+bNWrBgwVm/V11drczMTDkcDjmdTg0fPlzHjh2Tx+NRdna2JCkrK0sej0f19fW64IILNGzY\nMNlsNk2ZMkUejyecWwEAoF8L65mBbxw+fFjDhg1TUlKSJGnTpk06fvy4rrjiCrndbvn9fjmdzuDx\nTqdTPp+v23hiYqKamprk8/nOOLa+vj68GwIAoB+LSAzs2rVLt99+uyTpnnvu0ZgxY3TZZZdpxYoV\nevnll884PhAI9GrsXHm93v94DmCg4vUBmCMiMVBdXa3HHntMkoKn/SVp6tSp2r17tyZOnKhPP/00\nON7Y2CiXyyWXyyWfz6e4uLhuY36//4xjeyM1NbWPdvRPymr7fk4gAkLy+gAQMT0FftjfM9DY2Kjz\nzz9fDodDgUBAc+fO1YkTJyR9HQmjR4/WpEmTtHfvXrW3t6uxsVFNTU0aNWqUMjIyVFFRIUnas2eP\nMjMzdckll6i1tVV//etfdfr0aVVVVSkjIyPc2wIAoN8K+5mBf77Gb1mWZs2apblz52rQoEEaOnSo\nFi9erEGDBmnWrFnKz8+XZVkqLCyUzWbTnDlz9PDDDysvL0/x8fHasGGDJKmwsFAFBQWSpOnTp2vE\niBHh3hYAAP2WFeiLi+/9kNfrDclp0LylZ77nAeiPStffHeklAOhDPf3c4w6EAAAYjhgAAMBwxAAA\nAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAAgOGI\nAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAA\nwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4ezifrLq6WkuWLNHo0aMlSVde\neaXuvfdeLV26VJ2dnUpKStKGDRvkcDhUXl6ubdu2yWazadasWcrJyVFHR4eWLVumzz//XFFRUSoq\nKtKll16q2tpaFRYWSpLGjBmjlStXhnNbAAD0a2E/M3Dddddp+/bt2r59ux5//HFt2rRJeXl5Ki0t\n1eWXX65du3apra1Nmzdv1osvvqjt27dr27Ztam5u1uuvv674+Hi98sormj9/voqLiyVJa9askdvt\n1s6dO9Xa2qp9+/aFe1sAAPRbEb9MUF1drR/96EeSpKysLHk8Hh06dEjjx49XXFycYmJiNGHCBNXU\n1Mjj8Sg7O1uSlJ6erpqaGrW3t6uhoUHJycnd5gAAAL0T1ssEknTs2DHNnz9fX375pRYtWqRTp07J\n4XBIkhITE+Xz+eT3++V0OoOPcTqdZ4zbbDZZliW/36/4+Pjgsd/MAQAAeiesMfC9731PixYt0o9/\n/GPV19frnnvuUWdnZ/D7gUDgrI87l/F/d+zZeL3eXh8LmIbXB2COsMbA0KFDNX36dEnSZZddpgsv\nvFBHjhzRV199pZiYGDU2Nsrlcsnlcsnv9wcf19TUpGuuuUYul0s+n09jx45VR0eHAoGAkpKS1Nzc\nHDz2mzl6IzU1tW83KElltX0/JxABIXl9AIiYngI/rO8ZKC8v1/PPPy9J8vl8+uKLL3THHXeosrJS\nkrRnzx5lZmYqJSVFR44c0YkTJ3Ty5EnV1NQoLS1NGRkZqqiokCRVVVVp4sSJio6O1siRI3Xw4MFu\ncwAAgN4J65mBqVOn6qGHHtKbb76pjo4OFRYWaty4cXrkkUdUVlamiy++WDNmzFB0dLQKCgo0b948\nWZalhQsXKi4uTtOnT9f+/fs1e/ZsORwOrV27VpLkdru1fPlydXV1KSUlRenp6eHcFgAA/ZoVOJeL\n7AOI1+sNyWnQvKUv9/mcQCSUrr870ksA0Id6+rkX8Y8WAgCAyCIGAAAwHDEAAIDhiAEAAAxHDAAA\nYDhiAAAAwxEDAAAYjhgAAMBwxAAAAIYjBgAAMBwxAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4Y\nAADAcMQAAACGIwYAADAcMQAAgOGIAQAADEcMAABgOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAw\nHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYzh7uJ1y/fr28Xq9Onz6t++67T2+99ZY++OADJSQk\nSJLmzZunH/7whyovL9e2bdtks9k0a9Ys5eTkqKOjQ8uWLdPnn3+uqKgoFRUV6dJLL1Vtba0KCwsl\nSWPGjNHKlSvDvS0AAPqtsMbAgQMH9NFHH6msrEzHjx/X7bffrkmTJunBBx9UVlZW8Li2tjZt3rxZ\nu3btUnR0tGbOnKns7GxVVVUpPj5excXFevvtt1VcXKyNGzdqzZo1crvdSk5OVkFBgfbt26cpU6aE\nc2sAAPRbYb1M8IMf/EC//vWvJUnx8fE6deqUOjs7zzju0KFDGj9+vOLi4hQTE6MJEyaopqZGHo9H\n2dnZkqT09HTV1NSovb1dDQ0NSk5OliRlZWXJ4/GEb1MAAPRzYT0zEBUVpdjYWEnSrl27dMMNNygq\nKko7duzQ1q1blZiYqMcff1x+v19OpzP4OKfTKZ/P123cZrPJsiz5/X7Fx8cHj01MTJTP5+vVerxe\nbx/uDhhYeH0A5gj7ewYk6Y033tCuXbv0wgsv6OjRo0pISNC4ceP03HPP6emnn9a1117b7fhAIHDW\nec42/u+OPZvU1NRzW3hvlNX2/ZxABITk9QEgYnoK/LB/muCPf/yjfvOb36ikpERxcXGaPHmyxo0b\nJ0maOnWq6urq5HK55Pf7g49pamqSy+WSy+UK/tbf0dGhQCCgpKQkNTc3B49tbGyUy+UK76YAAOjH\nwhoDLS0tWr9+vZ599tngpwcWL16s+vp6SVJ1dbVGjx6tlJQUHTlyRCdOnNDJkydVU1OjtLQ0ZWRk\nqKKiQpJUVVWliRMnKjo6WiNHjtTBgwclSXv27FFmZmY4twUAQL8W1ssEu3fv1vHjx/XAAw8Ex+64\n4w498MADGjRokGJjY1VUVKSYmBgVFBRo3rx5sixLCxcuVFxcnKZPn679+/dr9uzZcjgcWrt2rSTJ\n7XZr+fLl6urqUkpKitLT08O5LQAA+jUrcC4X2QcQr9cbkmuieUtf7vM5gUgoXX93pJcAoA/19HOP\nOxACAGA4YgAAAMNF5KOFANDX5m5dEuklAH3ixf/5ddifkzMDAAAYjhgAAMBwxAAAAIYjBgAAMBwx\nAACA4YgBAAAMRwwAAGA4YgAAAMMRAwAAGI4YAADAcMQAAACGIwYAADAcMQAAgOGIAQAADEcMAABg\nOGIAAADDEQMAABiOGAAAwHDEAAAAhiMGAAAwHDEAAIDhiAEAAAxHDAAAYDhiAAAAwxEDAAAYjhgA\nAMBwxAAAAIazR3oBfemJJ57QoUOHZFmW3G63kpOTI70kAAD+6w2YGHj33Xf12WefqaysTB9//LHc\nbrfKysoivSwAAP7rDZjLBB6PR9OmTZMkXXHFFfryyy/V2toa4VUBAPDfb8DEgN/v15AhQ4JfO51O\n+Xy+CK4IAID+YcBcJvhXgUDgW4/xer19/rwFd43t8zmBSAjF6yOUFiffE+klAH0iEq+9ARMDLpdL\nfr8/+HVTU5OSkpL+7fGpqanhWBYAAP/1BsxlgoyMDFVWVkqSPvjgA7lcLg0ePDjCqwIA4L/fgDkz\nMGHCBF111VXKzc2VZVlasWJFpJcEAEC/YAV6c3EdAAAMWAPmMgEAAPhuiAEAAAxHDKBfeeKJJ3TX\nXXcpNzdXhw8fjvRyAKPU1dVp2rRp2rFjR6SXgj42YN5AiIGPW04DkdPW1qZVq1Zp8uTJkV4KQoAz\nA+g3uOU0EDkOh0MlJSVyuVyRXgpCgBhAv8Etp4HIsdvtiomJifQyECLEAPotPhULAH2DGEC/ca63\nnAYA9A4xgH6DW04DQGhwB0L0K7/85S918ODB4C2nx47lr0QC4XD06FGtW7dODQ0NstvtGjp0qJ56\n6iklJCREemnoA8QAAACG4zIBAACGIwYAADAcMQAAgOGIAQAADEcMAABgOGIAwHf2+9//PqTz19TU\nqL6+PqTPAYAYAPAddXZ26plnngnpc/z2t78lBoAw4E8YA/hO3G63Ghoa9NOf/lQpKSnyeDySpIsu\nukgbNmxQdHS0JkyYoJkzZ6qrq0v/+7//q1/84hc6dOiQLrzwQl100UUaMmSIfv7zn+vAgQPavHmz\nAoGA7Ha7Vq1apdraWlVUVOjw4cN69NFH+dO5QAhxZgDAd7J48WI5nU4999xzGjRokEpLS7Vz5061\ntLTo7bffliS1tbVpypQpeuyxx+TxeHT48GG9+uqr2rhxow4cOCBJOnXqlFasWKGnnnpKO3bsUH5+\nvtavX6/s7GyNGzdOy5YtIwSAEOPMAID/iN1ul81mU15enux2uz755BMdP35c0td/WXLChAmSpA8/\n/FBpaWmKiopSbGysMjMzJUnqrpXWAAABjklEQVQfffSRfD6fFi9eLOnryw+WZUVmM4ChiAEA/xGv\n16vXXntNr732mmJjY3X//fd3+350dLQkqaurSzbb/52M/Ob/HQ6HLr74Ym3fvj18iwbQDZcJAHwn\nNptNp0+f1hdffKHhw4crNjZWDQ0Nev/999Xe3n7G8SNHjtT777+vQCCgU6dOBS8lfO9739Px48dV\nV1cnSXrvvfdUVlYmSbIsSx0dHeHbFGAo/lARgO/k9OnTuuOOO2S329XV1aVBgwZp9OjRGj9+vDZv\n3qytW7fq5ptv1gcffCC73a7Tp09r6dKl+stf/qJhw4bpggsu0LBhw7R48WLt379fv/rVr3TeeedJ\nkn7xi19o5MiRevbZZ/XKK6/I7XbrxhtvjPCOgYGLGAAQFi0tLXrjjTc0Y8YMWZal+fPn65ZbbtEt\nt9wS6aUBxuM9AwDC4vzzz1dNTY1eeuklnXfeeRoxYoRuvvnmSC8LgDgzAACA8XgDIQAAhiMGAAAw\nHDEAAIDhiAEAAAxHDAAAYDhiAAAAw/0/usjgJBC0YqAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u84UXvUuw6g2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment(x,y,t=2):\n",
        "    xs,xn = [],[]\n",
        "    for i in range(t):\n",
        "        mask = y>0\n",
        "        x1 = x[mask].copy()\n",
        "        ids = np.arange(x1.shape[0])\n",
        "        for c in range(x1.shape[1]):\n",
        "            np.random.shuffle(ids)\n",
        "            x1[:,c] = x1[ids][:,c]\n",
        "        xs.append(x1)\n",
        "\n",
        "    for i in range(t//2):\n",
        "        mask = y==0\n",
        "        x1 = x[mask].copy()\n",
        "        ids = np.arange(x1.shape[0])\n",
        "        for c in range(x1.shape[1]):\n",
        "            np.random.shuffle(ids)\n",
        "            x1[:,c] = x1[ids][:,c]\n",
        "        xn.append(x1)\n",
        "\n",
        "    xs = np.vstack(xs)\n",
        "    xn = np.vstack(xn)\n",
        "    ys = np.ones(xs.shape[0])\n",
        "    yn = np.zeros(xn.shape[0])\n",
        "    x = np.vstack([x,xs,xn])\n",
        "    y = np.concatenate([y,ys,yn])\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KdD3AmxJ6Wpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "###Default 0.90127 second trial with 20 folds"
      ]
    },
    {
      "metadata": {
        "id": "4icampYhxWho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCUmITGDALBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Run from other colab GPu 20 Folds"
      ]
    },
    {
      "metadata": {
        "id": "r_J5b2QaABNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'device_type':'gpu',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XI-CsWSR_syC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Trial 2 GPU, Dart, learning rate and higher number of iterations"
      ]
    },
    {
      "metadata": {
        "id": "WJo8ubMx_rX1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,  \n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 3,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "005-Wm7GxZ7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kfold = 15\n",
        "folds = StratifiedKFold(n_splits=kfold, shuffle=False, random_state=44000)\n",
        "num_folds = 11\n",
        "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
        "\n",
        "#folds = KFold(n_splits=num_folds, random_state=2319)\n",
        "oof = np.zeros(len(train_df))\n",
        "getVal = np.zeros(len(train_df))\n",
        "predictions = np.zeros(len(target))\n",
        "feature_importance_df = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3tcbcg0xnLU",
        "colab_type": "code",
        "outputId": "6523380e-afcf-4c8b-9aee-2d8a9a4953d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3139
        }
      },
      "cell_type": "code",
      "source": [
        "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
        "    \n",
        "    X_train, y_train = train_df.iloc[trn_idx][features], target.iloc[trn_idx]\n",
        "    X_valid, y_valid = train_df.iloc[val_idx][features], target.iloc[val_idx]\n",
        "    \n",
        "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
        "    X_tr = pd.DataFrame(X_tr)\n",
        "    \n",
        "    print(\"Fold idx:{}\".format(fold_ + 1))\n",
        "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
        "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
        "    \n",
        "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 3000)\n",
        "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
        "    getVal[val_idx]+= clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
        "    \n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"feature\"] = features\n",
        "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
        "    fold_importance_df[\"fold\"] = fold_ + 1\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "    \n",
        "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold idx:1\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882989\tvalid_1's auc: 0.873197\n",
            "[10000]\ttraining's auc: 0.899106\tvalid_1's auc: 0.889668\n",
            "[15000]\ttraining's auc: 0.905535\tvalid_1's auc: 0.896777\n",
            "[20000]\ttraining's auc: 0.908702\tvalid_1's auc: 0.900275\n",
            "[25000]\ttraining's auc: 0.910669\tvalid_1's auc: 0.902107\n",
            "[30000]\ttraining's auc: 0.912149\tvalid_1's auc: 0.903073\n",
            "[35000]\ttraining's auc: 0.913409\tvalid_1's auc: 0.90346\n",
            "[40000]\ttraining's auc: 0.914611\tvalid_1's auc: 0.903774\n",
            "[45000]\ttraining's auc: 0.915749\tvalid_1's auc: 0.903864\n",
            "[50000]\ttraining's auc: 0.916832\tvalid_1's auc: 0.903928\n",
            "Early stopping, best iteration is:\n",
            "[48556]\ttraining's auc: 0.91652\tvalid_1's auc: 0.903985\n",
            "Fold idx:2\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882604\tvalid_1's auc: 0.868914\n",
            "[10000]\ttraining's auc: 0.899094\tvalid_1's auc: 0.883565\n",
            "[15000]\ttraining's auc: 0.905694\tvalid_1's auc: 0.889824\n",
            "[20000]\ttraining's auc: 0.908933\tvalid_1's auc: 0.89241\n",
            "[25000]\ttraining's auc: 0.910923\tvalid_1's auc: 0.893906\n",
            "[30000]\ttraining's auc: 0.912435\tvalid_1's auc: 0.89459\n",
            "[35000]\ttraining's auc: 0.91368\tvalid_1's auc: 0.895093\n",
            "[40000]\ttraining's auc: 0.914851\tvalid_1's auc: 0.895244\n",
            "[45000]\ttraining's auc: 0.91596\tvalid_1's auc: 0.895287\n",
            "Early stopping, best iteration is:\n",
            "[42377]\ttraining's auc: 0.91539\tvalid_1's auc: 0.895341\n",
            "Fold idx:3\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882597\tvalid_1's auc: 0.876273\n",
            "[10000]\ttraining's auc: 0.898778\tvalid_1's auc: 0.892949\n",
            "[15000]\ttraining's auc: 0.905206\tvalid_1's auc: 0.899578\n",
            "[20000]\ttraining's auc: 0.908458\tvalid_1's auc: 0.902574\n",
            "[25000]\ttraining's auc: 0.910448\tvalid_1's auc: 0.90409\n",
            "[30000]\ttraining's auc: 0.911957\tvalid_1's auc: 0.904571\n",
            "[35000]\ttraining's auc: 0.913274\tvalid_1's auc: 0.904832\n",
            "[40000]\ttraining's auc: 0.914464\tvalid_1's auc: 0.904886\n",
            "Early stopping, best iteration is:\n",
            "[37883]\ttraining's auc: 0.913982\tvalid_1's auc: 0.904979\n",
            "Fold idx:4\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882854\tvalid_1's auc: 0.864091\n",
            "[10000]\ttraining's auc: 0.899298\tvalid_1's auc: 0.878737\n",
            "[15000]\ttraining's auc: 0.905818\tvalid_1's auc: 0.884269\n",
            "[20000]\ttraining's auc: 0.909017\tvalid_1's auc: 0.887101\n",
            "[25000]\ttraining's auc: 0.910992\tvalid_1's auc: 0.888367\n",
            "[30000]\ttraining's auc: 0.912467\tvalid_1's auc: 0.889224\n",
            "[35000]\ttraining's auc: 0.913745\tvalid_1's auc: 0.889589\n",
            "[40000]\ttraining's auc: 0.914903\tvalid_1's auc: 0.889665\n",
            "Early stopping, best iteration is:\n",
            "[37844]\ttraining's auc: 0.914403\tvalid_1's auc: 0.889697\n",
            "Fold idx:5\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882277\tvalid_1's auc: 0.885236\n",
            "[10000]\ttraining's auc: 0.898679\tvalid_1's auc: 0.900631\n",
            "[15000]\ttraining's auc: 0.905238\tvalid_1's auc: 0.906112\n",
            "[20000]\ttraining's auc: 0.908367\tvalid_1's auc: 0.908424\n",
            "[25000]\ttraining's auc: 0.910374\tvalid_1's auc: 0.909157\n",
            "[30000]\ttraining's auc: 0.911853\tvalid_1's auc: 0.909738\n",
            "Early stopping, best iteration is:\n",
            "[29706]\ttraining's auc: 0.911775\tvalid_1's auc: 0.909802\n",
            "Fold idx:6\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882764\tvalid_1's auc: 0.869033\n",
            "[10000]\ttraining's auc: 0.899346\tvalid_1's auc: 0.884052\n",
            "[15000]\ttraining's auc: 0.905939\tvalid_1's auc: 0.889229\n",
            "[20000]\ttraining's auc: 0.90922\tvalid_1's auc: 0.891564\n",
            "[25000]\ttraining's auc: 0.911209\tvalid_1's auc: 0.892545\n",
            "[30000]\ttraining's auc: 0.91269\tvalid_1's auc: 0.892978\n",
            "[35000]\ttraining's auc: 0.913953\tvalid_1's auc: 0.89317\n",
            "Early stopping, best iteration is:\n",
            "[36514]\ttraining's auc: 0.914323\tvalid_1's auc: 0.893227\n",
            "Fold idx:7\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882347\tvalid_1's auc: 0.87491\n",
            "[10000]\ttraining's auc: 0.898772\tvalid_1's auc: 0.89155\n",
            "[15000]\ttraining's auc: 0.905503\tvalid_1's auc: 0.897671\n",
            "[20000]\ttraining's auc: 0.908784\tvalid_1's auc: 0.900246\n",
            "[25000]\ttraining's auc: 0.910796\tvalid_1's auc: 0.901225\n",
            "[30000]\ttraining's auc: 0.912268\tvalid_1's auc: 0.901433\n",
            "[35000]\ttraining's auc: 0.913563\tvalid_1's auc: 0.90154\n",
            "Early stopping, best iteration is:\n",
            "[35439]\ttraining's auc: 0.913672\tvalid_1's auc: 0.901565\n",
            "Fold idx:8\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.88227\tvalid_1's auc: 0.876574\n",
            "[10000]\ttraining's auc: 0.898789\tvalid_1's auc: 0.89205\n",
            "[15000]\ttraining's auc: 0.905343\tvalid_1's auc: 0.897797\n",
            "[20000]\ttraining's auc: 0.908567\tvalid_1's auc: 0.900308\n",
            "[25000]\ttraining's auc: 0.910582\tvalid_1's auc: 0.90131\n",
            "[30000]\ttraining's auc: 0.912053\tvalid_1's auc: 0.901871\n",
            "[35000]\ttraining's auc: 0.913311\tvalid_1's auc: 0.901985\n",
            "Early stopping, best iteration is:\n",
            "[36081]\ttraining's auc: 0.913563\tvalid_1's auc: 0.902065\n",
            "Fold idx:9\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.88176\tvalid_1's auc: 0.880318\n",
            "[10000]\ttraining's auc: 0.89831\tvalid_1's auc: 0.895844\n",
            "[15000]\ttraining's auc: 0.904937\tvalid_1's auc: 0.901074\n",
            "[20000]\ttraining's auc: 0.908132\tvalid_1's auc: 0.903233\n",
            "[25000]\ttraining's auc: 0.910146\tvalid_1's auc: 0.904184\n",
            "[30000]\ttraining's auc: 0.911599\tvalid_1's auc: 0.904673\n",
            "[35000]\ttraining's auc: 0.912861\tvalid_1's auc: 0.904791\n",
            "[40000]\ttraining's auc: 0.914024\tvalid_1's auc: 0.904848\n",
            "Early stopping, best iteration is:\n",
            "[38378]\ttraining's auc: 0.913656\tvalid_1's auc: 0.90489\n",
            "Fold idx:10\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.881622\tvalid_1's auc: 0.879235\n",
            "[10000]\ttraining's auc: 0.898295\tvalid_1's auc: 0.894328\n",
            "[15000]\ttraining's auc: 0.904913\tvalid_1's auc: 0.899474\n",
            "[20000]\ttraining's auc: 0.908126\tvalid_1's auc: 0.901382\n",
            "[25000]\ttraining's auc: 0.91013\tvalid_1's auc: 0.902088\n",
            "[30000]\ttraining's auc: 0.911662\tvalid_1's auc: 0.902322\n",
            "[35000]\ttraining's auc: 0.912931\tvalid_1's auc: 0.902326\n",
            "Early stopping, best iteration is:\n",
            "[33555]\ttraining's auc: 0.912579\tvalid_1's auc: 0.902454\n",
            "Fold idx:11\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.881972\tvalid_1's auc: 0.870579\n",
            "[10000]\ttraining's auc: 0.898655\tvalid_1's auc: 0.887548\n",
            "[15000]\ttraining's auc: 0.905251\tvalid_1's auc: 0.894238\n",
            "[20000]\ttraining's auc: 0.908488\tvalid_1's auc: 0.896872\n",
            "[25000]\ttraining's auc: 0.910521\tvalid_1's auc: 0.898237\n",
            "[30000]\ttraining's auc: 0.912014\tvalid_1's auc: 0.898845\n",
            "[35000]\ttraining's auc: 0.913327\tvalid_1's auc: 0.899112\n",
            "[40000]\ttraining's auc: 0.914512\tvalid_1's auc: 0.899204\n",
            "[45000]\ttraining's auc: 0.91562\tvalid_1's auc: 0.899325\n",
            "Early stopping, best iteration is:\n",
            "[43744]\ttraining's auc: 0.915344\tvalid_1's auc: 0.899376\n",
            "Fold idx:12\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882017\tvalid_1's auc: 0.877777\n",
            "[10000]\ttraining's auc: 0.898336\tvalid_1's auc: 0.892812\n",
            "[15000]\ttraining's auc: 0.905003\tvalid_1's auc: 0.898677\n",
            "[20000]\ttraining's auc: 0.908224\tvalid_1's auc: 0.901522\n",
            "[25000]\ttraining's auc: 0.91023\tvalid_1's auc: 0.902821\n",
            "[30000]\ttraining's auc: 0.911705\tvalid_1's auc: 0.903449\n",
            "[35000]\ttraining's auc: 0.912987\tvalid_1's auc: 0.903631\n",
            "[40000]\ttraining's auc: 0.91416\tvalid_1's auc: 0.903644\n",
            "[45000]\ttraining's auc: 0.915295\tvalid_1's auc: 0.9037\n",
            "Early stopping, best iteration is:\n",
            "[44199]\ttraining's auc: 0.915111\tvalid_1's auc: 0.903714\n",
            "Fold idx:13\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882286\tvalid_1's auc: 0.881211\n",
            "[10000]\ttraining's auc: 0.898705\tvalid_1's auc: 0.895976\n",
            "[15000]\ttraining's auc: 0.905282\tvalid_1's auc: 0.901299\n",
            "[20000]\ttraining's auc: 0.908554\tvalid_1's auc: 0.903387\n",
            "[25000]\ttraining's auc: 0.91056\tvalid_1's auc: 0.90432\n",
            "[30000]\ttraining's auc: 0.912012\tvalid_1's auc: 0.904652\n",
            "[35000]\ttraining's auc: 0.91329\tvalid_1's auc: 0.904657\n",
            "Early stopping, best iteration is:\n",
            "[32283]\ttraining's auc: 0.912602\tvalid_1's auc: 0.904742\n",
            "Fold idx:14\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.881885\tvalid_1's auc: 0.883833\n",
            "[10000]\ttraining's auc: 0.898218\tvalid_1's auc: 0.901001\n",
            "[15000]\ttraining's auc: 0.904824\tvalid_1's auc: 0.907544\n",
            "[20000]\ttraining's auc: 0.908012\tvalid_1's auc: 0.910222\n",
            "[25000]\ttraining's auc: 0.909968\tvalid_1's auc: 0.91142\n",
            "[30000]\ttraining's auc: 0.911433\tvalid_1's auc: 0.911891\n",
            "[35000]\ttraining's auc: 0.912744\tvalid_1's auc: 0.91213\n",
            "[40000]\ttraining's auc: 0.913954\tvalid_1's auc: 0.912268\n",
            "Early stopping, best iteration is:\n",
            "[40467]\ttraining's auc: 0.914066\tvalid_1's auc: 0.912309\n",
            "Fold idx:15\n",
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[5000]\ttraining's auc: 0.882576\tvalid_1's auc: 0.875286\n",
            "[10000]\ttraining's auc: 0.898965\tvalid_1's auc: 0.888321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J5NRbgsHx5zY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n >> CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNp1im2SyxlW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
        "#submission = pd.DataFrame()\n",
        "submission[\"target\"] = predictions\n",
        "submission.to_csv(\"submission_lgbm_3Leaves.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J5qV3WTCYDtQ",
        "colab_type": "code",
        "outputId": "e67e9cc3-16a4-4107-ca09-9eeaf725c512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM/python-package\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gk6t-S5IyyIr",
        "colab_type": "code",
        "outputId": "e9839b59-ff1b-4d84-fa1c-7d84bd3ee774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>0.138678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>0.274713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>0.227017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>0.312622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>0.057724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ID_code    target\n",
              "0  test_0  0.138678\n",
              "1  test_1  0.274713\n",
              "2  test_2  0.227017\n",
              "3  test_3  0.312622\n",
              "4  test_4  0.057724"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "Gnlz0iPUzxvt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###https://www.kaggle.com/jesucristo/santander-magic-lgb-0-901"
      ]
    },
    {
      "metadata": {
        "id": "7ECNdTgWzveD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}